{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sE0oWeYIBFOp",
    "outputId": "834967c2-9d98-493c-f135-7f63658e151e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/speaker_trainer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-26 01:09:13.409284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/echuraev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/echuraev/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet34\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import fbeta_score\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from emotiefflib.facial_analysis import EmotiEffLibRecognizer\n",
    "import numpy as np\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "import joblib\n",
    "from joblib import load\n",
    "import string\n",
    "import moviepy.editor as mp_editor\n",
    "import whisper_timestamped\n",
    "from aniemore.models import HuggingFaceModel\n",
    "from aniemore.recognizers.voice import VoiceRecognizer\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import scipy.io.wavfile as wavf\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from pystoi import stoi\n",
    "#from google.colab import drive\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import display\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pmONhWWAMYr"
   },
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Xzxw49MgAWAe"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingBCEWithLogitsLossFlat(BCEWithLogitsLossFlat):\n",
    "    \"\"\"\n",
    "    Modified loss function.\n",
    "    \"\"\"\n",
    "    def init(self, eps:float=0.1, **kwargs):\n",
    "        self.eps = eps\n",
    "        super().init(thresh=0.2, **kwargs)\n",
    "\n",
    "    def call(self, inp, targ, **kwargs):\n",
    "        # https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/166833#929222\n",
    "        targ_smooth = targ.float() * (1. - self.eps) + 0.5 * self.eps\n",
    "        return super().call(inp, targ_smooth, **kwargs)\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Tuned resnet 34 model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=19):\n",
    "        \"\"\"\n",
    "        Initialize resnet34 model and change last layer.\n",
    "        :param num_classes: int number of outputs.\n",
    "        \"\"\"\n",
    "        super(CustomResNet, self).__init__()\n",
    "        resnet = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        in_features = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(in_features, num_classes)\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, model, threshold=0.7, k=4):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.train_loss_mean = []\n",
    "        self.train_acc_mean = []\n",
    "        self.train_k_acc = []\n",
    "        self.val_loss_mean = []\n",
    "        self.val_acc_mean = []\n",
    "        self.val_k_acc = []\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Initialize loss function.\n",
    "        :param y_hat: prediction.\n",
    "        :param y: real values.\n",
    "        :return: loss function.\n",
    "        \"\"\"\n",
    "        loss_fn = LabelSmoothingBCEWithLogitsLossFlat()\n",
    "        return loss_fn(y_hat, y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Step of the training loop.\n",
    "        :param batch: batch for training.\n",
    "        :param batch_idx: index of trained batch.\n",
    "        :return: loss calculated on this step.\n",
    "        \"\"\"\n",
    "        images, attributes = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.adversarial_loss(outputs, attributes)\n",
    "        self.train_loss_mean.append(loss)\n",
    "        accuracy = self.calculate_accuracy(outputs, attributes)\n",
    "        k_acc = self.top_k_accuracy(outputs, attributes)\n",
    "        self.train_acc_mean.append(accuracy)\n",
    "        self.train_k_acc.append(k_acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Step of the validation loop.\n",
    "        :param batch: batch for validation.\n",
    "        :param batch_idx: index of validation batch.\n",
    "        :return: dictionary with validation loss and accuracy.\n",
    "        \"\"\"\n",
    "        images, attributes = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.adversarial_loss(outputs, attributes)\n",
    "        self.val_loss_mean.append(loss)\n",
    "        accuracy = self.calculate_accuracy(outputs, attributes)\n",
    "        k_acc = self.top_k_accuracy(outputs, attributes)\n",
    "        self.val_acc_mean.append(accuracy)\n",
    "        self.val_k_acc.append(k_acc)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": accuracy, \"val_k_acc\": k_acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Initialize optimizer.\n",
    "        :return: optimizer.\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Calculate mean values when validation epoch ends.\n",
    "        \"\"\"\n",
    "        loss = sum(self.val_loss_mean) / len(self.val_loss_mean)\n",
    "        self.val_loss_mean = []\n",
    "        acc = sum(self.val_acc_mean) / len(self.val_acc_mean)\n",
    "        self.val_acc_mean = []\n",
    "        k_acc = sum(self.val_k_acc) / len(self.val_k_acc)\n",
    "        self.val_k_acc = []\n",
    "        self.log(\"val epoch end loss\", loss, prog_bar=True)\n",
    "        self.log(\"val epoch end acc\", acc, prog_bar=True)\n",
    "        self.log(\"val epoch end k acc\", k_acc, prog_bar=True)\n",
    "\n",
    "    def calculate_accuracy(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Calculate the quality of the model.\n",
    "        :param outputs: model outputs.\n",
    "        :param targets: targets: real values.\n",
    "        :return: float value - accuracy.\n",
    "        \"\"\"\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        binary_mask = (probs >= self.threshold).float()\n",
    "        accuracy = fbeta_score(binary_mask, targets, beta=2, average='samples')\n",
    "        return accuracy\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Calculate mean values when trining epoch ends.\n",
    "        \"\"\"\n",
    "        loss = sum(self.train_loss_mean) / len(self.train_loss_mean)\n",
    "        self.train_loss_mean = []\n",
    "        acc = sum(self.train_acc_mean) / len(self.train_acc_mean)\n",
    "        self.train_acc_mean = []\n",
    "        k_acc = sum(self.train_k_acc) / len(self.train_k_acc)\n",
    "        self.train_k_acc = []\n",
    "        self.log(\"train epoch end loss\", loss, prog_bar=True)\n",
    "        self.log(\"train epoch end acc\", acc, prog_bar=True)\n",
    "        self.log(\"train epoch end k acc\", k_acc, prog_bar=True)\n",
    "\n",
    "    def top_k_accuracy(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Calculate accuracy among k most probable classes.\n",
    "        :param outputs: model outputs.\n",
    "        :param targets: real values.\n",
    "        :return: float value - accuracy.\n",
    "        \"\"\"\n",
    "        topk_values, topk_indices = torch.topk(outputs, self.k, dim=1)\n",
    "        correct_count = 0\n",
    "        for i in range(topk_indices.size(0)):\n",
    "            for j in range(topk_indices.size(1)):\n",
    "                if targets[i, topk_indices[i, j]] == 1:\n",
    "                    correct_count += 1\n",
    "        accuracy = correct_count / (outputs.size(0) * self.k)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cqe512LWAQP6"
   },
   "outputs": [],
   "source": [
    "class Clothes:\n",
    "    attributes = ['floral', 'graphic', 'striped', 'embroidered', 'solid', 'lattice',\n",
    "                  'long_sleeve', 'short_sleeve', 'sleeveless', 'maxi_length',\n",
    "                  'mini_length', 'crew_neckline', 'v_neckline', 'square_neckline',\n",
    "                  'no_neckline', 'denim', 'tight', 'loose', 'conventional']\n",
    "    not_acceptable_attributes = ['sleeveless', 'mini_length', 'denim', 'tight', 'loose']\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize transforms.\n",
    "        \"\"\"\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def compute_image_sharpness(self, image):\n",
    "        \"\"\"\n",
    "        Calculate sharpness of one image.\n",
    "        :param image: image to process.\n",
    "        :return: float value - sharpness of image.\n",
    "        \"\"\"\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.Laplacian(gray_image, cv2.CV_64F).var()\n",
    "\n",
    "    def choose_sharpest_image(self, images):\n",
    "        \"\"\"\n",
    "        Choose sharpest image for future assessing.\n",
    "        :param images: frames for choosing.\n",
    "        :return: sharpest image.\n",
    "        \"\"\"\n",
    "        sharpest_image = None\n",
    "        max_sharpness = 0\n",
    "\n",
    "        for image in images:\n",
    "            sharpness = self.compute_image_sharpness(image)\n",
    "            if sharpness > max_sharpness:\n",
    "                max_sharpness = sharpness\n",
    "                sharpest_image = image\n",
    "\n",
    "        return sharpest_image\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        \"\"\"\n",
    "        Transform image into model input.\n",
    "        :param image: image for processing.\n",
    "        :return: tensor - transformed image.\n",
    "        \"\"\"\n",
    "        mp_pose = mp.solutions.pose\n",
    "        pose = mp_pose.Pose()\n",
    "\n",
    "        image_h, image_w, _ = image.shape\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # Identify bound box.\n",
    "            x_min, y_min, x_max, y_max = image_w, image_h, 0, 0\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                x, y = int(landmark.x * image_w), int(landmark.y * image_h)\n",
    "                x_min = max(0, min(x_min, x))\n",
    "                y_min = max(0, min(y_min, y))\n",
    "                x_max = min(image_w - 1, max(x_max, x))\n",
    "                y_max = min(image_h - 1, max(y_max, y))\n",
    "            image = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        pose.close()\n",
    "        pil_image = Image.fromarray(image)\n",
    "        image = self.transform(pil_image)\n",
    "        return image\n",
    "\n",
    "    def check_arrays(self, arr1, arr2):\n",
    "        \"\"\"\n",
    "        Check presence of first array elements in second array.\n",
    "        :param arr1: array for checking elements.\n",
    "        :param arr2: second array for processing.\n",
    "        :return: bool value if none of elements in first array is in the second.\n",
    "        \"\"\"\n",
    "        for elem in arr1:\n",
    "            if elem in arr2:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def assess_appearance(self, frames):\n",
    "        \"\"\"\n",
    "        Assess clothes attributes.\n",
    "        :param frames: frames for choosing best frame for processing.\n",
    "        :return: bool value if clothes is acceptable.\n",
    "        \"\"\"\n",
    "        model = CustomResNet()\n",
    "        custom_model = CustomModel(model)\n",
    "\n",
    "        path = \"./saved_model_modified.pth\"\n",
    "\n",
    "        custom_model.model.load_state_dict(torch.load(path))\n",
    "        image = self.choose_sharpest_image(frames)\n",
    "        image = self.transform_image(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        custom_model.eval()\n",
    "        output = custom_model(image)\n",
    "        pred = F.softmax(output, dim=1)\n",
    "        topk_values, topk_indices = torch.topk(pred, 3, dim=1)\n",
    "        captions = []\n",
    "        for i in range(topk_indices.size(0)):\n",
    "            for j in range(topk_indices.size(1)):\n",
    "                captions.append(Clothes.attributes[topk_indices[i, j]])\n",
    "        return self.check_arrays(captions, Clothes.not_acceptable_attributes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iciHQjvCAY7K"
   },
   "outputs": [],
   "source": [
    "class DrawResults:\n",
    "    def __init__(self, path, dist=10, good_color=(0,128,0), bad_color=(60,20,220)):\n",
    "        self.video_path = path\n",
    "        self.dist = dist\n",
    "        self.right_color = good_color\n",
    "        self.not_right_color = bad_color\n",
    "\n",
    "    def draw_frames(self, frame, text, color_flag):\n",
    "        \"\"\"\n",
    "        Draw results on video frames.\n",
    "        :param frames: frames for processing.\n",
    "        :return: processed frames.\n",
    "        \"\"\"\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        x = 20\n",
    "        y = 30\n",
    "        font_scale = 0.5\n",
    "        thickness = 1\n",
    "        count = 1\n",
    "        for i in range(len(text)):\n",
    "            if color_flag[i]:\n",
    "                color = self.right_color\n",
    "            else:\n",
    "                color = self.not_right_color\n",
    "            if text[i] is not None:\n",
    "                frame = cv2.putText(frame, text[i], (x, y * count), font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "                count += 1\n",
    "        return frame\n",
    "\n",
    "    def draw_angle(self, frame, length, color):\n",
    "        \"\"\"\n",
    "        Draw lines for correct angle.\n",
    "        :param frame: image for drawing.\n",
    "        :param length: length of speaker's bound box.\n",
    "        :param color: red if angle is incorrect, green otherwise.\n",
    "        :return: new frame with angle lines.\n",
    "        \"\"\"\n",
    "        image_orig = frame.copy()\n",
    "        height, width = frame.shape[:2]\n",
    "        center_x = width // 2\n",
    "        line_length = length // 2\n",
    "        line_thickness = 5\n",
    "        line_offset_top = height // 3 + int(0.15 * height)\n",
    "        line_offset_bottom = height // 3 - int(0.15 * height)\n",
    "        font_color = self.right_color\n",
    "        if not color:\n",
    "            font_color = self.not_right_color\n",
    "        cv2.line(frame, (center_x - line_length, height), (center_x - line_length, 0), font_color, line_thickness)\n",
    "        cv2.line(frame, (center_x + line_length, height), (center_x + line_length, 0), font_color, line_thickness)\n",
    "        cv2.line(frame, (center_x - line_length, line_offset_top), (center_x + line_length, line_offset_top),\n",
    "                 font_color, line_thickness)\n",
    "        cv2.line(frame, (center_x - line_length, line_offset_bottom), (center_x + line_length, line_offset_bottom),\n",
    "                 font_color, line_thickness)\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        bottom_left_corner_text = (center_x - line_length, line_offset_top - 20)\n",
    "        font_scale = 0.5\n",
    "        line_type = 1\n",
    "        cv2.putText(frame, 'Рекомендуемый уровень глаз', bottom_left_corner_text, font, font_scale, font_color,\n",
    "                    line_type)\n",
    "        image_out = cv2.addWeighted(frame, 0.3, image_orig, 0.7, 0.0)\n",
    "        return image_out\n",
    "\n",
    "    def draw(self, output_path, text, colors, angle, angle_color):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "        try:\n",
    "            segment_duration = self.dist\n",
    "            segment_frame_count = math.ceil(fps * segment_duration)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            i = 0\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                ind = i // segment_frame_count\n",
    "                text_elements = [row[ind] for row in text]\n",
    "                colors_elements = [row[ind] for row in colors]\n",
    "                frame = self.draw_frames(frame, text_elements, colors_elements)\n",
    "                if len(angle) > 0 and angle[ind] is not None:\n",
    "                    color = True\n",
    "                    if i % segment_frame_count in angle_color[ind]:\n",
    "                        color = False\n",
    "                    frame = self.draw_angle(frame, angle[ind], color)\n",
    "                out.write(frame)\n",
    "                i += 1\n",
    "        except Exception as e:\n",
    "            print(e.args)\n",
    "        finally:\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2dSwx3owAafI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745618963.485087 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1745618963.490256 6246118 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618963.494640 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n"
     ]
    }
   ],
   "source": [
    "class VideoEmotions:\n",
    "    face_detection = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.3)\n",
    "    model_name = 'enet_b0_8_best_afew'\n",
    "    face_mesh = mp.solutions.face_mesh.FaceMesh()\n",
    "\n",
    "    def __init__(self, device='cpu', model='EmotiEffLib', engine=\"onnx\"):\n",
    "        \"\"\"\n",
    "        Initialize model and device.\n",
    "        :param device: cpu or gpu.\n",
    "        :param model: HSEmotion or deepFace.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        if model == 'EmotiEffLib':\n",
    "            self.predictor = EmotiEffLibRecognizer(engine=engine, model_name=VideoEmotions.model_name, device=device)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_main_face(frame):\n",
    "        \"\"\"\n",
    "        Crop image to get main face on the frame.\n",
    "        @return: cropped image.\n",
    "        \"\"\"\n",
    "        results = VideoEmotions.face_detection.process(frame)\n",
    "        main_face = None\n",
    "        max_score = 0\n",
    "        if results.detections is not None:\n",
    "            for detection in results.detections:\n",
    "                if detection.score[0] > max_score:\n",
    "                    main_face = detection\n",
    "                    max_score = detection.score[0]\n",
    "            if main_face is not None:\n",
    "                bbox = main_face.location_data.relative_bounding_box\n",
    "                image_height, image_width, _ = frame.shape\n",
    "                x, y, w, h = int(bbox.xmin * image_width), int(bbox.ymin * image_height), \\\n",
    "                    int(bbox.width * image_width), int(bbox.height * image_height)\n",
    "                main_face = frame[y:y + h, x:x + w]\n",
    "        return main_face\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_emotion_percentage(emotion_list):\n",
    "        \"\"\"\n",
    "        Calculate percentage of each element in the list.\n",
    "        :param emotion_list: list for calculation.\n",
    "        :return: dictionary with percentages of each element.\n",
    "        \"\"\"\n",
    "        total_frames = len(emotion_list)\n",
    "        emotion_percentage = {}\n",
    "        for emotion in emotion_list:\n",
    "            if emotion in emotion_percentage.keys():\n",
    "                emotion_percentage[emotion] += 1\n",
    "            else:\n",
    "                emotion_percentage[emotion] = 1\n",
    "        for emotion in emotion_percentage.keys():\n",
    "            emotion_percentage[emotion] = (emotion_percentage[emotion] / total_frames) * 100\n",
    "        return emotion_percentage\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_emotion_change_frequency(emotion_list):\n",
    "        \"\"\"\n",
    "        calculate the percentage of changing emotions between two seconds.\n",
    "        :param emotion_list: list to calculate changes in it.\n",
    "        :return: frequency of changing emotions.\n",
    "        \"\"\"\n",
    "        total_frames = len(emotion_list)\n",
    "        emotion_changes = 0\n",
    "        for i in range(1, total_frames):\n",
    "            if emotion_list[i] != emotion_list[i - 1]:\n",
    "                emotion_changes += 1\n",
    "        emotion_change_frequency = emotion_changes / total_frames\n",
    "        return emotion_change_frequency\n",
    "\n",
    "    def process_frames(self, frames):\n",
    "        \"\"\"\n",
    "        Predict emotions on each frame.\n",
    "        :param frames: frames for processing.\n",
    "        :return: main emotions and probabilities for each frame.\n",
    "        \"\"\"\n",
    "        imgs = frames\n",
    "        faces = list(map(VideoEmotions.get_main_face, imgs))\n",
    "        emotions, scores = [], []\n",
    "        for face in faces:\n",
    "            if face is not None:\n",
    "                try:\n",
    "                    emotion, score = self.predictor.predict_emotions(face, logits=False)\n",
    "                    emotions.append(emotion)\n",
    "                    scores.append(score)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        return emotions, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P__hf405Ab8R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1745618963.499144 6246132 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618963.508295 6246129 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "class GazeDirection:\n",
    "    LEFT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398, 286, 258, 257, 259, 260]\n",
    "    RIGHT_IRIS = [468, 470, 469, 472, 471]\n",
    "    RIGHT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246, 30, 29, 28, 27, 56]\n",
    "    LEFT_IRIS = [473, 475, 474, 477, 476]\n",
    "\n",
    "    def __init__(self, threshold=0.1):\n",
    "        \"\"\"\n",
    "        Initialize prediction model and threshold.\n",
    "        :param threshold: float value - acceptable displacement of iris.\n",
    "        \"\"\"\n",
    "\n",
    "        path = \"./face_landmarker_v2_with_blendshapes.task\"\n",
    "\n",
    "        model_file = open(path, \"rb\")\n",
    "        model_data = model_file.read()\n",
    "        model_file.close()\n",
    "        base_options = python.BaseOptions(model_asset_buffer=model_data)\n",
    "        options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                               output_face_blendshapes=True,\n",
    "                                               output_facial_transformation_matrixes=True,\n",
    "                                               num_faces=1)\n",
    "        self.detector = vision.FaceLandmarker.create_from_options(options)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def count_displacement(self, eye_coords, iris_coords):\n",
    "        \"\"\"\n",
    "        Calculate the position of iris in percent relatively center.\n",
    "        :param eye_coords: all coordinates of eye.\n",
    "        :param iris_coords: all coordinates of iris.\n",
    "        :return: percent of x and y axis - position of an iris.\n",
    "        \"\"\"\n",
    "        max_x = (max(eye_coords, key=lambda item: item[0]))[0]\n",
    "        min_x = (min(eye_coords, key=lambda item: item[0]))[0]\n",
    "        max_y = (max(eye_coords, key=lambda item: item[1]))[1]\n",
    "        min_y = (min(eye_coords, key=lambda item: item[1]))[1]\n",
    "        width = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "        iris_x = iris_coords[0][0]\n",
    "        iris_y = iris_coords[0][1]\n",
    "        percent_x = (2 * iris_x - width - 2 * min_x) / width\n",
    "        percent_y = (2 * iris_y - height - 2 * min_y) / height\n",
    "        return percent_x, percent_y\n",
    "\n",
    "    def process_gaze(self, right_x, right_y, left_x, left_y):\n",
    "        \"\"\"\n",
    "        Asses gaze.\n",
    "        :param right_x: x position of right iris.\n",
    "        :param right_y: y position of right iris.\n",
    "        :param left_x: x position of left iris.\n",
    "        :param left_y: y position of left iris.\n",
    "        :return: string value - gaze direction.\n",
    "        \"\"\"\n",
    "        x = (right_x + left_x) / 2\n",
    "        y = (right_y + left_y) / 2\n",
    "        if y > 0.45:\n",
    "            result = \"down \"\n",
    "        elif y < 0.2:\n",
    "            result = \"up \"\n",
    "        else:\n",
    "            result = \"\"\n",
    "\n",
    "        if abs(x) > self.threshold and x > 0:\n",
    "            result += \"right\"\n",
    "        elif abs(x) > self.threshold and x < 0:\n",
    "            result += \"left\"\n",
    "        else:\n",
    "            result += \"center\"\n",
    "        return result\n",
    "\n",
    "    def landmarks_detection(self, img_width, img_height, face_landmarks, ind):\n",
    "        \"\"\"\n",
    "        Transform coordinates into pixels of image.\n",
    "        :param img_width: width of an image.\n",
    "        :param img_height: height of an image.\n",
    "        :param face_landmarks: not transformed landmarks.\n",
    "        :param ind: indexes of required points.\n",
    "        :return: transformed coordinates.\n",
    "        \"\"\"\n",
    "        mesh_coord = [(int(face_landmarks[i].x * img_width), int(face_landmarks[i].y * img_height)) for i in ind]\n",
    "        return mesh_coord\n",
    "\n",
    "    def gaze_detection(self, frames):\n",
    "        \"\"\"\n",
    "        Calculate direction of eyes on each frame.\n",
    "        :param frames: frames for processing.\n",
    "        :return: list with string results for all frames.\n",
    "        \"\"\"\n",
    "        result_list = []\n",
    "        for frame in frames:\n",
    "            image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "            results = self.detector.detect(image)\n",
    "            frame_width = frame.shape[0]\n",
    "            frame_height = frame.shape[1]\n",
    "            try:\n",
    "                face_landmarks = results.face_landmarks[0]\n",
    "                left_iris_coords = self.landmarks_detection(frame_width, frame_height, face_landmarks, GazeDirection.LEFT_IRIS)\n",
    "                right_iris_coords = self.landmarks_detection(frame_width, frame_height, face_landmarks, GazeDirection.RIGHT_IRIS)\n",
    "                left_eye_coords = self.landmarks_detection(frame_width, frame_height, face_landmarks, GazeDirection.LEFT_EYE)\n",
    "                right_eye_coords = self.landmarks_detection(frame_width, frame_height, face_landmarks, GazeDirection.RIGHT_EYE)\n",
    "                right_x, right_y = self.count_displacement(right_eye_coords, right_iris_coords)\n",
    "                left_x, left_y = self.count_displacement(left_eye_coords, left_iris_coords)\n",
    "                res = self.process_gaze(right_x, right_y, left_x, left_y)\n",
    "                result_list.append(res)\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "        return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nwmfv4dlAdUD"
   },
   "outputs": [],
   "source": [
    "class Gestures:\n",
    "    body_angles = [[16, 14, 12], [14, 12, 11], [15, 13, 11], [12, 11, 13],\n",
    "                   [21, 15, 19], [19, 15, 17], [22, 16, 20], [20, 16, 18],\n",
    "                   [18, 20, 16, 14], [17, 19, 15, 13], [11, 0, 12]]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.body_res = {16: {'name': 'right elbow', 'res': []}, 14: {'name': 'right shoulder', 'res': []},\n",
    "                         15: {'name': 'left elbow', 'res': []},\n",
    "                         12: {'name': 'left shoulder', 'res': []},\n",
    "                         21: {'name': 'left thumb', 'res': []},\n",
    "                         19: {'name': 'left pinky', 'res': []}, 22: {'name': 'right thumb', 'res': []},\n",
    "                         20: {'name': 'right pinky', 'res': []},\n",
    "                         18: {'name': 'right wrist', 'res': []}, 17: {'name': 'left wrist', 'res': []},\n",
    "                         11: {'name': 'head', 'res': []}}\n",
    "\n",
    "    def get_vector_between_points(self, first_point, second_point):\n",
    "        \"\"\"\n",
    "        Calculate vector between two points in 2d.\n",
    "        :param first_point: list or array with 2 elements (x and y) - first point to calculate vector.\n",
    "        :param second_point: list or array with 2 elements (x and y) - second point to calculate vector.\n",
    "        :return: list wit x and y of calculated vector.\n",
    "        \"\"\"\n",
    "        x1, y1 = first_point[0], first_point[1]\n",
    "        x2, y2 = second_point[0], second_point[1]\n",
    "        vector = np.array([x2, y2]) - np.array([x1, y1])\n",
    "        return vector\n",
    "\n",
    "    def angle_between_vectors(self, v1, v2):\n",
    "        \"\"\"\n",
    "        Calculate angle in degrees between given vectors.\n",
    "        :param v1: list or array with 2 elements (x and y) - first vector.\n",
    "        :param v2: list or array with 2 elements (x and y) - second vector.\n",
    "        :return: float value [0:360] - angle between v1 and v2.\n",
    "        \"\"\"\n",
    "        dot_product = np.dot(v1, v2)\n",
    "        norm_v1 = np.linalg.norm(v1)\n",
    "        norm_v2 = np.linalg.norm(v2)\n",
    "        cos_theta = dot_product / (norm_v1 * norm_v2)\n",
    "        angle_rad = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "        # Check the angle of the sign and adjust it in the range from 0 to 360 degrees.\n",
    "        if np.cross(v1, v2) < 0:\n",
    "            angle_deg = 360 - angle_deg\n",
    "\n",
    "        return angle_deg\n",
    "\n",
    "    def min_angle_difference(self, angle1, angle2):\n",
    "        \"\"\"\n",
    "        Get min differance between two angles.\n",
    "        :param angle1: float value [0:360] - first value in degrees.\n",
    "        :param angle2: float value [0:360] - second value in degrees.\n",
    "        :return: float value [0:360] - min angle between two angles in closed circle.\n",
    "        \"\"\"\n",
    "        diff1 = abs(angle1 - angle2)\n",
    "        diff2 = 360 - diff1\n",
    "        return min(diff1, diff2)\n",
    "\n",
    "    def point_between(self, point1, point2):\n",
    "        \"\"\"\n",
    "        Calculate point between 2 points in 2d.\n",
    "        :param point1: landmark with x and y attributes - first point.\n",
    "        :param point2: landmark with x and y attributes - second point.\n",
    "        :return: list with x and y of point between 2 given points.\n",
    "        \"\"\"\n",
    "        return [(point1.x + point2.x) / 2, (point1.y + point2.y) / 2]\n",
    "\n",
    "    def calculate_angles(self, landmarks, mean_angle):\n",
    "        \"\"\"\n",
    "        calculate the displacement of the joints between frames.\n",
    "        :param landmarks: coordinates of the main joints.\n",
    "        :param mean_angle: dictionary for calculation results.\n",
    "        :return: dictionary with results.\n",
    "        \"\"\"\n",
    "        for angles in Gestures.body_angles:\n",
    "            if all(landmarks[angle].visibility >= 0.5 for angle in angles):\n",
    "                point_second = [landmarks[angles[-1]].x, landmarks[angles[-1]].y]\n",
    "                point_mid = [landmarks[angles[-2]].x, landmarks[angles[-2]].y]\n",
    "                if len(angles) > 3:\n",
    "                    point_first = self.point_between(landmarks[angles[0]], landmarks[angles[1]])\n",
    "                else:\n",
    "                    point_first = [landmarks[angles[0]].x, landmarks[angles[0]].y]\n",
    "                v1 = self.get_vector_between_points(point_first, point_mid)\n",
    "                v2 = self.get_vector_between_points(point_mid, point_second)\n",
    "                angle = self.angle_between_vectors(v1, v2)\n",
    "                if mean_angle[angles[0]]['prev'] is not None:\n",
    "                    mean_angle[angles[0]]['res'] += self.min_angle_difference(angle, mean_angle[angles[0]]['prev'])\n",
    "                    mean_angle[angles[0]]['count'] += 1\n",
    "                else:\n",
    "                    mean_angle[angles[0]]['prev'] = angle\n",
    "            else:\n",
    "                mean_angle[angles[0]]['prev'] = None\n",
    "        return mean_angle\n",
    "\n",
    "    def process_velocity(self, frames):\n",
    "        \"\"\"\n",
    "        Count angle displacement for all frames.\n",
    "        :param frames: frames to process.\n",
    "        :return: dictionary with results for each joint.\n",
    "        \"\"\"\n",
    "        mp_pose = mp.solutions.pose\n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            mean_angle = {}\n",
    "            for angle in Gestures.body_angles:\n",
    "                mean_angle[angle[0]] = {}\n",
    "                mean_angle[angle[0]]['prev'] = None\n",
    "                mean_angle[angle[0]]['count'] = 0\n",
    "                mean_angle[angle[0]]['res'] = 0\n",
    "            for image in frames:\n",
    "                results = pose.process(image)\n",
    "                try:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    mean_angle = self.calculate_angles(landmarks, mean_angle)\n",
    "                except Exception as ex:\n",
    "                    continue\n",
    "            for angle in Gestures.body_angles:\n",
    "                if mean_angle[angle[0]]['count'] > 0:\n",
    "                    result = mean_angle[angle[0]]['res'] / mean_angle[angle[0]]['count']\n",
    "                    self.body_res[angle[0]]['res'].append(round(result, 2))\n",
    "                else:\n",
    "                    self.body_res[angle[0]]['res'].append(0)\n",
    "\n",
    "    def get_result(self):\n",
    "        \"\"\"\n",
    "        Get result angles for body parts.\n",
    "        :return: dictionary with body parts as keys and angles as values.\n",
    "        \"\"\"\n",
    "        return {value['name']: value['res'] for key, value in self.body_res.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8sNmDDrMAe9Z"
   },
   "outputs": [],
   "source": [
    "class Perspective:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize model for detection.\n",
    "        \"\"\"\n",
    "        self.detector = PoseDetector(staticMode=False,\n",
    "                                modelComplexity=1,\n",
    "                                smoothLandmarks=True,\n",
    "                                enableSegmentation=False,\n",
    "                                smoothSegmentation=True,\n",
    "                                detectionCon=0.5,\n",
    "                                trackCon=0.5)\n",
    "\n",
    "    def point_between(self, point1, point2):\n",
    "        \"\"\"\n",
    "        Calculate point between 2 points in 2d.\n",
    "        :param point1: list with x and y of first point.\n",
    "        :param point2: list with x and y of second point.\n",
    "        :return: list with x and y of mid point.\n",
    "        \"\"\"\n",
    "        return [(point1[0] + point2[0]) / 2, (point1[1] + point2[1]) / 2]\n",
    "\n",
    "    def count_brightness(self, frames):\n",
    "        \"\"\"\n",
    "        Asses lightning on frames.\n",
    "        :param frames: list with frames to process.\n",
    "        :return: string value - lightning.\n",
    "        \"\"\"\n",
    "        dark = 0\n",
    "        optimal = 0\n",
    "        bright = 0\n",
    "        for frame in frames:\n",
    "            gray_image = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            mean_brightness = np.mean(gray_image)\n",
    "            if mean_brightness < 100:\n",
    "                dark += 1\n",
    "            elif mean_brightness > 200:\n",
    "                bright += 1\n",
    "            else:\n",
    "                optimal += 1\n",
    "        dark /= len(frames)\n",
    "        optimal /= len(frames)\n",
    "        bright /= len(frames)\n",
    "        if dark >= optimal and dark >= bright:\n",
    "            return 0\n",
    "        elif bright >= dark and bright >= optimal:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def check_correct_pose(self, bounding_box, eye_coords, image_width, image_height):\n",
    "        \"\"\"\n",
    "        Check if speaker in a right position.\n",
    "        :param bounding_box: coordinates of the speakers bound box.\n",
    "        :param eye_coords: eyes coordinates.\n",
    "        :param image_width: width of an image.\n",
    "        :param image_height: height of an image.\n",
    "        :return: 1 or 0 - if position is correct.\n",
    "        \"\"\"\n",
    "        x_center = image_width // 2\n",
    "        y_third_line = image_height // 3\n",
    "        x, y, x_len, y_len = bounding_box[\"bbox\"]\n",
    "        if abs(x + x_len / 2 - x_center) > 0.2 * x_center:\n",
    "            return False\n",
    "\n",
    "        # Check eye position according rule of the third.\n",
    "        eye_x, eye_y = eye_coords\n",
    "        if eye_y < y_third_line - 0.15 * image_height or eye_y > y_third_line + 0.15 * image_height:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def count_angle(self, frames):\n",
    "        \"\"\"\n",
    "        Count percent of incorrect frames.\n",
    "        :param frames: frames to process.\n",
    "        :return: percent of incorrect frames.\n",
    "        \"\"\"\n",
    "        incorrect_pose = 0\n",
    "        bbox_length = 0\n",
    "        inc_index = []\n",
    "        ind = 0\n",
    "        for frame in frames:\n",
    "            img = self.detector.findPose(frame, draw=False)\n",
    "            lm_list, bbox_info = self.detector.findPosition(img, draw=False, bboxWithHands=False)\n",
    "            if len(lm_list) == 0:\n",
    "                incorrect_pose += 1\n",
    "                continue\n",
    "            right_coords = [lm_list[5][0], lm_list[5][1]]\n",
    "            left_coords = [lm_list[2][0], lm_list[2][1]]\n",
    "            height, width = frame.shape[:2]\n",
    "            if not self.check_correct_pose(bbox_info, self.point_between(right_coords, left_coords), width, height):\n",
    "                inc_index.append(ind)\n",
    "                incorrect_pose += 1\n",
    "            ind += 1\n",
    "            length = bbox_info['bbox'][2] - bbox_info['bbox'][0]\n",
    "            if length > bbox_length:\n",
    "                bbox_length = length\n",
    "        return incorrect_pose / len(frames), bbox_length, inc_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pwHDIcaMAhFl"
   },
   "outputs": [],
   "source": [
    "class VideoSubsystem:\n",
    "    acceptable_velocity = {'right elbow': [5, 50], 'left elbow': [5, 50], 'left shoulder': [2, 25],\n",
    "                           'right shoulder': [2, 25], 'left thumb': [0, 30], 'left pinky': [3, 40],\n",
    "                           'right thumb': [0, 30], 'right pinky': [3, 40], 'right wrist': [3, 40],\n",
    "                           'left wrist': [3, 40], 'head': [0, 12]}\n",
    "\n",
    "    def __init__(self, path, inappropriate_emotions, emotions=True, gesticulation=True, angle=True, gaze=True, clothes=True,\n",
    "                 device='cpu', dist=5, acceptable_angle=0.6):\n",
    "        self.fps = None\n",
    "        self.inappropriate_emotions = inappropriate_emotions\n",
    "        self.device = device\n",
    "        self.video_path = path\n",
    "        self.emotions = emotions\n",
    "        self.gesticulation = gesticulation\n",
    "        self.angle = angle\n",
    "        self.gaze = gaze\n",
    "        self.clothes = clothes\n",
    "        self.dist = dist\n",
    "        self.acceptable_angle = acceptable_angle\n",
    "\n",
    "        path = \"./model_first.joblib\"\n",
    "        self.emotion_model = load(path)\n",
    "        self.emotion_list = []\n",
    "        self.emotion_inappropriate_percentage = []\n",
    "        self.gesture_list = []\n",
    "        self.angle_list = []\n",
    "        self.gaze_list = []\n",
    "        self.lightning = []\n",
    "        self.angle_len = []\n",
    "        self.inc_ind = []\n",
    "        self.clothes_estimation = None\n",
    "\n",
    "    def get_emotions(self):\n",
    "        return self.emotion_list\n",
    "\n",
    "    def get_gestures(self):\n",
    "        return self.gesture_list\n",
    "\n",
    "    def get_angle(self):\n",
    "        return self.angle_list\n",
    "\n",
    "    def get_gaze(self):\n",
    "        return self.gaze_list\n",
    "\n",
    "    def get_lightning(self):\n",
    "        return self.lightning\n",
    "\n",
    "    def get_angle_len(self):\n",
    "        return self.angle_len\n",
    "\n",
    "    def get_clothes_estimation(self):\n",
    "        return self.clothes_estimation\n",
    "\n",
    "    def get_incorrect_angle_ind(self):\n",
    "        return self.inc_ind\n",
    "\n",
    "    def get_inappropriate_emotion_percentage(self):\n",
    "        return self.emotion_inappropriate_percentage\n",
    "    @staticmethod\n",
    "    def get_subarray(array, subset, ind):\n",
    "        \"\"\"\n",
    "        Get subarray.\n",
    "        :param array: array to get subarray from it.\n",
    "        :param subset: number of elements in subarray.\n",
    "        :param ind: index of array from which subarray starts.\n",
    "        :return: subarray.\n",
    "        \"\"\"\n",
    "        last_ind = min(ind + subset, len(array))\n",
    "        return array[ind:last_ind]\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_percentage(percent_list):\n",
    "        \"\"\"\n",
    "        Calculate percent of each element in the list.\n",
    "        :param percent_list: list for calculating percents.\n",
    "        :return: dictionary with elements of list as keys and percents as values.\n",
    "        \"\"\"\n",
    "        total_frames = len(percent_list)\n",
    "        percentage = {}\n",
    "        for element in percent_list:\n",
    "            if element in percentage.keys():\n",
    "                percentage[element] += 1\n",
    "            else:\n",
    "                percentage[element] = 1\n",
    "        for element in percentage.keys():\n",
    "            percentage[element] = (percentage[element] / total_frames) * 100\n",
    "\n",
    "        return percentage\n",
    "\n",
    "    def process_emotions(self, frames):\n",
    "        \"\"\"\n",
    "        Evaluate emotionality of video fragment.\n",
    "        :param frames: list of frames for evaluation.\n",
    "        :return: string value - emotionality.\n",
    "        \"\"\"\n",
    "        total_frames = len(frames)\n",
    "        emotion_class = VideoEmotions()\n",
    "        emotion_results = []\n",
    "        fps = int(self.fps)\n",
    "        for i in range(0, total_frames, int(fps)):\n",
    "            sec_frames = self.get_subarray(frames, fps, i)[::self.dist]\n",
    "            emotions, scores = emotion_class.process_frames(sec_frames)\n",
    "            emotions = [emo[0] for emo in emotions]\n",
    "            percentages = VideoSubsystem.calculate_percentage(emotions)\n",
    "            try:\n",
    "                max_emotion = max(percentages, key=percentages.get)\n",
    "                emotion_results.append(max_emotion)\n",
    "            except Exception as ex:\n",
    "                print(ex.args[0])\n",
    "                emotion_results.append('emotion not determined')\n",
    "        frequency = emotion_class.calculate_emotion_change_frequency(emotion_results)\n",
    "        percentages = VideoSubsystem.calculate_percentage(emotion_results)\n",
    "        features = [frequency]\n",
    "        for element in ['Sadness', 'Disgust', 'Fear', 'Neutral', 'Happiness', 'Anger',\n",
    "        'Contempt']:\n",
    "            if element in percentages.keys():\n",
    "                features.append(percentages[element])\n",
    "            else:\n",
    "                features.append(0.0)\n",
    "        res = self.emotion_model.predict([features])[0]\n",
    "        percent_res = 0.0\n",
    "        for element in self.inappropriate_emotions:\n",
    "            if element in percentages.keys():\n",
    "                percent_res += percentages[element]\n",
    "        return res, percent_res * 0.01\n",
    "\n",
    "    def replace_values_with_condition(self, dictionary):\n",
    "        \"\"\"\n",
    "        Change values for values in rating scale.\n",
    "        :param dictionary: dictionary with unprocessed values.\n",
    "        :return: dictionary with processed values.\n",
    "        \"\"\"\n",
    "        for key, value in dictionary.items():\n",
    "            min_val = VideoSubsystem.acceptable_velocity[key][0]\n",
    "            max_val = VideoSubsystem.acceptable_velocity[key][1]\n",
    "            for i in range(len(value)):\n",
    "                if value[i] < min_val:\n",
    "                    value[i] = '0'\n",
    "                elif value[i] > max_val:\n",
    "                    value[i] = '2'\n",
    "                else:\n",
    "                    value[i] = '1'\n",
    "            dictionary[key] = value\n",
    "        return dictionary\n",
    "\n",
    "    def process_gesticulation(self, frames, duration=10):\n",
    "        \"\"\"\n",
    "        Estimate velocity of the speaker.\n",
    "        :param frames: list of frames for estimation.\n",
    "        :param duration: number of seconds for estimation.\n",
    "        :return: estimated velocity.\n",
    "        \"\"\"\n",
    "        gesture = Gestures()\n",
    "        total_frames = len(frames)\n",
    "        fps = int(self.fps)\n",
    "        for i in range(0, total_frames, fps):\n",
    "            sec_frames = self.get_subarray(frames, fps, i)[::self.dist]\n",
    "            gesture.process_velocity(sec_frames)\n",
    "        res = gesture.get_result()\n",
    "        res = self.replace_values_with_condition(res)\n",
    "        result = []\n",
    "        key = list(res.keys())[0]\n",
    "        cycle = len(res[key])\n",
    "        for ind in range(cycle):\n",
    "            percent = []\n",
    "            for key in res.keys():\n",
    "                percent.append(res[key][ind])\n",
    "            percentage = VideoSubsystem.calculate_percentage(percent)\n",
    "            if '2' in percentage.keys():\n",
    "                result.append(2)\n",
    "            elif '0' in percentage.keys() and percentage['0'] > 70:\n",
    "                result.append(0)\n",
    "            else:\n",
    "                result.append(1)\n",
    "        all_percent = VideoSubsystem.calculate_percentage(result)\n",
    "        if 2 in all_percent.keys():\n",
    "            return 2\n",
    "        elif 0 in all_percent.keys() and all_percent[0] > 70:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def process_gaze(self, frames):\n",
    "        \"\"\"\n",
    "        Calculate percent of incorrect gaze.\n",
    "        :param frames: list of frames for processing.\n",
    "        :return: float value - percent of incorrect frames.\n",
    "        \"\"\"\n",
    "        model = GazeDirection()\n",
    "        percent = model.gaze_detection(frames)\n",
    "        percentages = VideoSubsystem.calculate_percentage(percent)\n",
    "        # max_key = max(percentages, key=percentages.get)\n",
    "        return (100 - percentages.get(\"center\", 0)) * 0.01\n",
    "\n",
    "    def process_angle(self, frames):\n",
    "        \"\"\"\n",
    "        Calculate incorrect angles.\n",
    "        :param frames: list of frames for processing.\n",
    "        :return: float value - percent of incorrect frames.\n",
    "        \"\"\"\n",
    "        perspective = Perspective()\n",
    "        brightness = perspective.count_brightness(frames[::self.dist])\n",
    "        percent, length, inc_ind = perspective.count_angle(frames)\n",
    "        return percent, length, brightness, inc_ind\n",
    "\n",
    "    def process_clothes(self, frames):\n",
    "        \"\"\"\n",
    "        Defines if clothes is appropriate.\n",
    "        :param frames: list of frames for processing.\n",
    "        :return: bool value if clothes is appropriate.\n",
    "        \"\"\"\n",
    "        clothes = Clothes()\n",
    "        return clothes.assess_appearance(frames)\n",
    "\n",
    "\n",
    "    def process_video(self, duration=10):\n",
    "        \"\"\"\n",
    "        Read for duration seconds and process frames.\n",
    "        :param output_path: new path of processed video.\n",
    "        :param duration: number of seconds to process in one cycle.\n",
    "        :return: dictionary with results.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        try:\n",
    "            self.fps = math.ceil(cap.get(cv2.CAP_PROP_FPS))\n",
    "            segment_duration = duration\n",
    "            segment_frame_count = math.ceil(cap.get(cv2.CAP_PROP_FPS) * segment_duration)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            for i in tqdm(range(0, frame_count, segment_frame_count)):\n",
    "                frames = []\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "                for j in range(segment_frame_count):\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    frames.append(frame)\n",
    "                if self.emotions:\n",
    "                    res, percent_res = self.process_emotions(frames)\n",
    "                    self.emotion_list.append(res)\n",
    "                    self.emotion_inappropriate_percentage.append(percent_res)\n",
    "                if self.gesticulation:\n",
    "                    res = self.process_gesticulation(frames)\n",
    "                    self.gesture_list.append(res)\n",
    "                if self.angle:\n",
    "                    res, length, brightness, inc_ind = self.process_angle(frames)\n",
    "                    self.angle_list.append(res)\n",
    "                    self.angle_len.append(length)\n",
    "                    self.lightning.append(brightness)\n",
    "                    self.inc_ind.append(inc_ind)\n",
    "                if self.gaze:\n",
    "                    res = self.process_gaze(frames)\n",
    "                    self.gaze_list.append(res)\n",
    "                if self.clothes and self.clothes_estimation is None:\n",
    "                    self.clothes_estimation = self.process_clothes(frames)\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXceJ2hYAh7R"
   },
   "source": [
    "## Speech Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3ZdTcjNXAj3e"
   },
   "outputs": [],
   "source": [
    "class AutomaticSpeechRecognition:\n",
    "    \"\"\"\n",
    "    Class for transcribing audio into text.\n",
    "    Creates speech text, words time intervals, unidentified noise time intervals.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, lang):\n",
    "        \"\"\"\n",
    "        Initialization of speech processing class\n",
    "        @param path: path to audio file\n",
    "        \"\"\"\n",
    "        clip = mp_editor.AudioFileClip(path)\n",
    "        self.path = path\n",
    "        self.duration = clip.duration\n",
    "        self.transcription = None\n",
    "        self.lang = lang\n",
    "\n",
    "    def get_speech_recognition(self):\n",
    "        \"\"\"\n",
    "        Translates audio to text, creates words lists with timestamps (with and without background noise)\n",
    "        \"\"\"\n",
    "        model = whisper_timestamped.load_model(\"large\")\n",
    "        # whisper timestamped allows to receive timestamps for each word and sentence, as well as\n",
    "        # noise timestamps\n",
    "        audio = whisper_timestamped.load_audio(self.path)\n",
    "        self.transcription = whisper_timestamped.transcribe(\n",
    "            model,\n",
    "            audio,\n",
    "            language=self.lang,\n",
    "            detect_disfluencies=True,\n",
    "            remove_punctuation_from_words=False)\n",
    "        correct_transcription = self.check_transcription()\n",
    "        # creation of transcription without punctuation marks\n",
    "        transcription = self.transcription[\"text\"].lower()\n",
    "        transcription = transcription.translate(str.maketrans('', '', string.punctuation))\n",
    "        transcription = \"\".join([ch for ch in transcription if ch not in string.digits])\n",
    "        cleaned_transcription = \" \".join(transcription.split())\n",
    "        word_arrays = self.get_words()\n",
    "        return cleaned_transcription, word_arrays, correct_transcription\n",
    "\n",
    "    def check_transcription(self):\n",
    "        \"\"\"\n",
    "        Checks if transcription is correct (if there are word doubles at the end of transcription)\n",
    "        @return: True if transcription is correct, False otherwise\n",
    "        \"\"\"\n",
    "        words = self.transcription[\"text\"].split()\n",
    "        segments = self.transcription[\"segments\"]\n",
    "        end_idx = len(segments)\n",
    "        # find first segment out of time range\n",
    "        for i in range(len(segments)):\n",
    "            if segments[i][\"end\"] > self.duration:\n",
    "                end_idx = i\n",
    "                break\n",
    "        # checks if there is no segments out of time range\n",
    "        if end_idx == len(segments):\n",
    "            return True\n",
    "        else:\n",
    "            # count words out of time range\n",
    "            extra_words = 0\n",
    "            for i in range(end_idx, len(segments)):\n",
    "                extra_words += len(segments[i][\"text\"].split())\n",
    "            # transcription correction\n",
    "            self.transcription[\"text\"] = \" \".join((self.transcription[\"text\"].split())[:len(words) - extra_words])\n",
    "            self.transcription[\"segments\"] = self.transcription[\"segments\"][:end_idx]\n",
    "            return False\n",
    "\n",
    "    def get_words(self):\n",
    "        \"\"\"\n",
    "        Creates lists with all words (with background noise), words without noise and only noise\n",
    "        @return: three lists with dicts of words and their timestamps\n",
    "        \"\"\"\n",
    "        all_words, all_words_without_noise, noise = [], [], []\n",
    "        for sentence in self.transcription[\"segments\"]:\n",
    "            for word in sentence[\"words\"]:\n",
    "                all_words.append(word)\n",
    "                if word[\"text\"] != \"[*]\":\n",
    "                    all_words_without_noise.append(word)\n",
    "                else:\n",
    "                    noise.append((word[\"start\"], word[\"end\"]))\n",
    "        return all_words_without_noise, noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y9BuXWo6ApcF"
   },
   "outputs": [],
   "source": [
    "class BackgroundNoise:\n",
    "    \"\"\"\n",
    "    Class for background noise detecting.\n",
    "    \"\"\"\n",
    "    # boundary values for size of time window and maximal acceptable noise percentage\n",
    "    params = {\n",
    "        \"noise_time_window\": 30,  # size of time window to view noise percentage\n",
    "        \"noise_percentage\": 0.45,  # maximal noise percentage\n",
    "    }\n",
    "\n",
    "    def __init__(self, noise):\n",
    "        \"\"\"\n",
    "        Initialization of background noise analysis class\n",
    "        @param noise: timestamps with background noise, list of two-element lists\n",
    "        \"\"\"\n",
    "        self.noise = noise\n",
    "\n",
    "    def get_high_noise_timestamps(self):\n",
    "        \"\"\"\n",
    "        Searches most noisy periods with the help of floating window\n",
    "        @return: Most noisy periods, list of two-element lists\n",
    "        \"\"\"\n",
    "        high_noise_timestamps = []\n",
    "        if len(self.noise) == 0:\n",
    "            return high_noise_timestamps\n",
    "        start_idx, end_idx = 0, 1\n",
    "        noise_sum = self.noise[0][1] - self.noise[0][0]\n",
    "        while end_idx < len(self.noise):\n",
    "            # searches for minimal time window larger than boundary value\n",
    "            if self.noise[end_idx][1] - self.noise[start_idx][0] < \\\n",
    "                    self.params[\"noise_time_window\"]:\n",
    "                noise_sum += self.noise[end_idx][1] - self.noise[end_idx][0]\n",
    "                end_idx += 1\n",
    "                continue\n",
    "            # check if the percentage of noise is larger than parameter\n",
    "            if noise_sum / (self.noise[end_idx][1] - self.noise[start_idx][0]) > \\\n",
    "                    self.params[\"noise_percentage\"]:\n",
    "                # if period intersects with previous one - they are united\n",
    "                if len(high_noise_timestamps) > 0 and high_noise_timestamps[-1][1] > \\\n",
    "                        self.noise[start_idx][0]:\n",
    "                    high_noise_timestamps[-1][1] = self.noise[end_idx][1]\n",
    "                # otherwise, new time period is appended\n",
    "                else:\n",
    "                    high_noise_timestamps.append(\n",
    "                        [self.noise[start_idx][0], self.noise[end_idx][1]])\n",
    "            noise_sum -= (self.noise[start_idx][1] - self.noise[start_idx][0])\n",
    "            start_idx += 1\n",
    "        return high_noise_timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KcfYui14Aq2M"
   },
   "outputs": [],
   "source": [
    "class AudioEmotions:\n",
    "    \"\"\"\n",
    "    Class for emotions detecting.\n",
    "    Counts percentage of preferred emotions and percentage of neutral emotion.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, analyzed_segment_len, negative_emotions):\n",
    "        \"\"\"\n",
    "        Initialization of emotion classification class\n",
    "        @param path: path to audio file\n",
    "        @param analyzed_segment_len: length of file segment to analyze separately\n",
    "        @param negative_emotions: list of preferred emotions\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.analyzed_segment_len = analyzed_segment_len\n",
    "        self.negative_emotions = negative_emotions\n",
    "        # paths for N-second sub clips\n",
    "        path = os.path.abspath(os.path.dirname(__file__))\n",
    "        self.subclip_path = os.path.abspath(os.path.join(path, \"file_processing/processing.wav\"))\n",
    "        self.subclip_modified_path = os.path.abspath(os.path.join(path, \"file_processing/processing2.wav\"))\n",
    "        # order of emotions in model\n",
    "        self.order = [\"happiness\", \"anger\", \"disgust\", \"neutral\", \"sadness\", \"enthusiasm\"]\n",
    "\n",
    "    def emotions_analysis(self):\n",
    "        \"\"\"\n",
    "        Analyzes speech per N seconds (see init params) and provides emotions probabilities\n",
    "        @return: lists with emotions probabilities\n",
    "        \"\"\"\n",
    "        model = VoiceRecognizer(model=HuggingFaceModel.Voice.Wav2Vec2)\n",
    "        clip = AudioFileClip(self.path)\n",
    "        duration = clip.duration\n",
    "        # number of file fragments to analyze\n",
    "        number_of_segments = math.ceil(duration / self.analyzed_segment_len)\n",
    "        negative_emotions_percentage = np.zeros(number_of_segments)\n",
    "        neutral_emotion_percentage = np.zeros(number_of_segments)\n",
    "        time = self.analyzed_segment_len\n",
    "        for i in tqdm(range(number_of_segments)):\n",
    "            # path to analyzed file fragment\n",
    "            subclip = clip.subclip(i * time, min(i * time + time, duration))\n",
    "            subclip.write_audiofile(self.subclip_path, logger=None)\n",
    "\n",
    "            # sub clip preprocessing to convert stereo to mono\n",
    "            self.audio_channels_processing()\n",
    "            emotions_percentages = model.recognize(self.subclip_modified_path, return_single_label=False)\n",
    "            # counting of preferred emotions percentage\n",
    "            for idx, emotion in enumerate(self.order):\n",
    "                if self.negative_emotions[idx]:\n",
    "                    negative_emotions_percentage[i] += emotions_percentages[emotion]\n",
    "                neutral_emotion_percentage[i] = emotions_percentages[\"neutral\"]\n",
    "\n",
    "        # deleting of intermediate files\n",
    "        file_paths = [self.subclip_path, self.subclip_modified_path]\n",
    "        for file_path in file_paths:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        return negative_emotions_percentage, neutral_emotion_percentage\n",
    "\n",
    "    def audio_channels_processing(self):\n",
    "        \"\"\"\n",
    "        Rewriting file to one channel if necessary\n",
    "        \"\"\"\n",
    "        audio_file = wave.open(self.subclip_path)\n",
    "        channels = audio_file.getnchannels()\n",
    "        sound = AudioSegment.from_wav(self.subclip_path)\n",
    "        if channels > 1:\n",
    "            sound = sound.set_channels(1)\n",
    "        # rewriting one channel file\n",
    "        sound.export(self.subclip_modified_path, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xhzIdkd7AsFw"
   },
   "outputs": [],
   "source": [
    "class FillerWordsAndPhrases:\n",
    "    \"\"\"\n",
    "    Class for filler words and phrases detecting.\n",
    "    Detects words and phrases from lists and as most common in speech.\n",
    "    \"\"\"\n",
    "    # maximal acceptable percentages and lists of filler words\n",
    "    params_ru = {\n",
    "        # multiplier for most common word or phrase occurrence to be compared with others\n",
    "        \"word_count_multiplier\": 0.1,\n",
    "        # minimal percentage for word or phrase to be considered common\n",
    "        \"occurrence_percentage\": 0.0001,\n",
    "        \"parasites\": [\"просто\", \"вот\", \"ну\", \"короче\", \"типа\", \"пожалуй\", \"кстати\", \"вообще\", \"буквально\", \"скажем\",\n",
    "                      \"блин\", \"допустим\", \"черт\", \"вроде\", \"круто\", \"прикинь\", \"прикиньте\", \"реально\", \"отпад\",\n",
    "                      \"отпадно\", \"клево\", \"капец\", \"норм\", \"слушай\", \"конечно\", \"наверное\", \"вероятно\", \"кажется\"],\n",
    "        \"parasite_phrases\": [\"так сказать\", \"как бы\", \"в натуре\", \"в общем\", \"в общемто\", \"в целом\", \"в принципе\",\n",
    "                             \"как говорится\", \"как сказать\", \"на фиг\", \"то есть\", \"это самое\", \"как его\", \"типа того\"]\n",
    "    }\n",
    "    params_en = {\n",
    "        # multiplier for most common word or phrase occurrence to be compared with others\n",
    "        \"word_count_multiplier\": 0.1,\n",
    "        # minimal percentage for word or phrase to be considered common\n",
    "        \"occurrence_percentage\": 0.0001,\n",
    "        \"parasites\": [\"like\", \"um\", \"uh\", \"well\", \"so\", \"just\", \"actually\", \"literally\", \"basically\", \"really\",\n",
    "                      \"seriously\", \"okay\", \"right\", \"honestly\", \"sure\", \"maybe\", \"perhaps\", \"kinda\", \"sorta\", \"totally\"],\n",
    "        \"parasite_phrases\": [\"you know\", \"i mean\", \"you see\", \"i guess\", \"i suppose\", \"the thing is\",\n",
    "                             \"let's say\", \"it's like\", \"at the end of the day\", \"and stuff\", \"or something\",\n",
    "                             \"you know what i mean\", \"to be honest\", \"in a way\", \"if you will\"]\n",
    "    }\n",
    "\n",
    "    def __init__(self, cleaned_transcription, lang):\n",
    "        \"\"\"\n",
    "        Initialization of filler words detection class\n",
    "        @param cleaned_transcription: text transcription without punctuation marks\n",
    "        \"\"\"\n",
    "        self.cleaned_transcription = cleaned_transcription\n",
    "        if lang == \"ru\":\n",
    "            self.params = self.params_ru\n",
    "        else:\n",
    "            self.params = self.params_en\n",
    "\n",
    "    def count_occurrences(self, min_len=5):\n",
    "        \"\"\"\n",
    "        Counts two-words phrases occurrences\n",
    "        @param min_len: minimal length in letters for phrase to be considered\n",
    "        @return: list of two-element lists, each with phrase and its occurrence\n",
    "        \"\"\"\n",
    "        pairs = dict()\n",
    "        words = self.cleaned_transcription.split()\n",
    "        for i in range(len(words) - 1):\n",
    "            # create two-word phrases\n",
    "            phrase = words[i] + ' ' + words[i + 1]\n",
    "            if len(phrase) > min_len:\n",
    "                # save phrases with acceptable length\n",
    "                if phrase not in pairs:\n",
    "                    pairs[phrase] = 0\n",
    "                pairs[phrase] += 1\n",
    "        phrases_from_list = {}\n",
    "\n",
    "        # rewrite phrases from list into separate dictionary\n",
    "        for phrase in self.params[\"parasite_phrases\"]:\n",
    "            if phrase in pairs:\n",
    "                phrases_from_list[phrase] = pairs[phrase]\n",
    "        phrase_dic = list(pairs.items())\n",
    "        phrases = sorted(phrase_dic, key=lambda x: -x[1])\n",
    "        return phrases, phrases_from_list\n",
    "\n",
    "    def find_worst_phrases(self, phrases):\n",
    "        \"\"\"\n",
    "        Takes most common phrases from all\n",
    "        @param phrases: all two-word phrases\n",
    "        @return: dictionary with key - phrases and value - their occurrences\n",
    "        \"\"\"\n",
    "        num_words = len(self.cleaned_transcription)\n",
    "        max_repeats = phrases[0][1]\n",
    "        # if all collocations appear one time - there are no most common phrases\n",
    "        if max_repeats == 1 or max_repeats / num_words < self.params[\"occurrence_percentage\"]:\n",
    "            return dict()\n",
    "        # maximal deviation from most common word or phrase occurrence\n",
    "        diff = round(max_repeats * self.params[\"word_count_multiplier\"])\n",
    "        worst_word_pairs = dict()\n",
    "        # find phrases with small deviation from most common one\n",
    "        for word_pair, cnt in phrases:\n",
    "            if cnt >= max_repeats - diff and cnt / num_words >= self.params[\"occurrence_percentage\"]:\n",
    "                worst_word_pairs[word_pair] = cnt\n",
    "        return worst_word_pairs\n",
    "\n",
    "    def get_one_words(self):\n",
    "        \"\"\"\n",
    "        Counts all filler words from params parasites\n",
    "        @return: frequency dictionary with key - words and value - their occurrences\n",
    "        \"\"\"\n",
    "        text_tokens = word_tokenize(self.cleaned_transcription)\n",
    "        text_tokens = [token.strip() for token in text_tokens if token in set(self.params[\"parasites\"])]\n",
    "        text = nltk.Text(text_tokens)\n",
    "        fdist = FreqDist(text)\n",
    "        return fdist\n",
    "\n",
    "    def find_worst_words(self, fdist):\n",
    "        \"\"\"\n",
    "        Takes most common filler words from all\n",
    "        @param fdist: frequency dictionary with key - words and value - their occurrences\n",
    "        @return: dictionary with key - words and value - their occurrences\n",
    "        \"\"\"\n",
    "        num_words = len(self.cleaned_transcription)\n",
    "        if len(fdist) == 0:\n",
    "            return dict()\n",
    "        # most common word appearance\n",
    "        max_repeats = fdist.most_common(1)[0][1]\n",
    "        if max_repeats == 1 or max_repeats / num_words < self.params[\"occurrence_percentage\"]:\n",
    "            return dict()\n",
    "        # maximal deviation from most common word or phrase occurrence\n",
    "        diff = round(max_repeats * self.params[\"word_count_multiplier\"])\n",
    "        idx = 1\n",
    "        # add words with high occurrence percentage\n",
    "        while idx <= len(fdist) and fdist.most_common(idx)[-1][1] >= max_repeats - diff and \\\n",
    "                fdist.most_common(idx)[-1][1] / num_words >= self.params[\"occurrence_percentage\"]:\n",
    "            idx += 1\n",
    "        worst_words = dict(fdist.most_common(idx - 1))\n",
    "        return worst_words\n",
    "\n",
    "    def get_filler_words_final(self):\n",
    "        \"\"\"\n",
    "        Concatenates all words and phrases into two dictionaries - all and most common filler words\n",
    "        @return: two dictionaries with words / phrases and their occurrences\n",
    "        \"\"\"\n",
    "        # find all and most common / listed phrases\n",
    "        phrases, phrases_from_list = self.count_occurrences()\n",
    "        worst_phrases = self.find_worst_phrases(phrases)\n",
    "\n",
    "        # find all and most common / listed words\n",
    "        fdist = self.get_one_words()\n",
    "        worst_words = self.find_worst_words(fdist)\n",
    "\n",
    "        # dicts with all and most common / list words and phrases\n",
    "        total_dict = dict(worst_phrases) | dict(fdist) | phrases_from_list\n",
    "        worst_dict = dict(worst_phrases) | dict(worst_words)\n",
    "        return total_dict, worst_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9kgD4plzAtYJ"
   },
   "outputs": [],
   "source": [
    "class Intelligibility:\n",
    "    \"\"\"\n",
    "    Class for intelligibility detecting.\n",
    "    Uses info from background noise analysis and high speech rate timestamps.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, all_words_without_noise, noise, analyzed_segment_len):\n",
    "        \"\"\"\n",
    "        Initialization of background noise analysis class\n",
    "        @param path: path to audio file\n",
    "        @param all_words_without_noise: list of all words and their timestamps\n",
    "        @param noise: timestamps with background noise, list of two-element lists\n",
    "        @param analyzed_segment_len: length of file segment to analyze separately\n",
    "        \"\"\"\n",
    "        self.noise = noise\n",
    "        self.path = path\n",
    "        self.all_words_without_noise = all_words_without_noise\n",
    "        self.analyzed_segment_len = analyzed_segment_len\n",
    "\n",
    "    def stoi_index(self):\n",
    "        \"\"\"\n",
    "        Counting short time objective intelligibility index per file fragment\n",
    "        @return: list with STOI indexes for each fragment\n",
    "        \"\"\"\n",
    "        # paths for file fragments\n",
    "        subclip_path = \"processing.wav\"\n",
    "        subclip_modified_path = \"processing2.wav\"\n",
    "\n",
    "        clip = AudioFileClip(self.path)\n",
    "        duration = clip.duration\n",
    "        # number of file segments to analyze\n",
    "        number_of_segments = math.ceil(duration / self.analyzed_segment_len)\n",
    "        indexes = np.zeros(number_of_segments)\n",
    "        for i in range(number_of_segments):\n",
    "            # file fragment (checks for len not out of file length)\n",
    "            subclip = clip.subclip(i * self.analyzed_segment_len,\n",
    "                                   min((i + 1) * self.analyzed_segment_len, clip.duration))\n",
    "            # it is ineffective to analyze too short fragments\n",
    "            if subclip.duration < 3:\n",
    "                indexes[i] = 0.5\n",
    "                continue\n",
    "            subclip.write_audiofile(subclip_path, logger=None)\n",
    "            data, rate = librosa.load(subclip_path)\n",
    "            # cleaning degraded speech signal\n",
    "            reduced_noise = nr.reduce_noise(y=data, sr=rate, thresh_n_mult_nonstationary=2, stationary=False)\n",
    "            wavf.write(subclip_modified_path, rate, reduced_noise)\n",
    "            # loading signal info\n",
    "            clean, fs = librosa.load(subclip_modified_path)\n",
    "            base, fs = librosa.load(subclip_path)\n",
    "            # counting and saving STOI indexes\n",
    "            index = stoi(clean, base, fs, extended=False)\n",
    "            indexes[i] = round(index, 3)\n",
    "\n",
    "        # deleting intermediate files\n",
    "        file_paths = [subclip_path, subclip_modified_path]\n",
    "        for file_path in file_paths:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        return indexes\n",
    "\n",
    "    def indirect_features(self):\n",
    "        \"\"\"\n",
    "        Analyses intelligibility of speech\n",
    "        @return: intervals with high speech and high levels of background noise\n",
    "        \"\"\"\n",
    "        # timestamps with fast speech rate\n",
    "        speech_rate = SpeechRate(self.all_words_without_noise)\n",
    "        _, fast_intervals = speech_rate.find_incorrect_speech_rate_intervals()\n",
    "        # timestapms with high background noise\n",
    "        noisy_intervals = BackgroundNoise(self.noise).get_high_noise_timestamps()\n",
    "\n",
    "        return fast_intervals, noisy_intervals\n",
    "\n",
    "    def get_intelligibility_features(self):\n",
    "        \"\"\"\n",
    "        Final method for aggregating file info\n",
    "        @return: lists with STOI indexes, intervals with high speech and high levels of background noise\n",
    "        \"\"\"\n",
    "        indexes = self.stoi_index()\n",
    "        fast_intervals, noisy_intervals = self.indirect_features()\n",
    "        return indexes, fast_intervals, noisy_intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xvN4lmS6Axqg"
   },
   "outputs": [],
   "source": [
    "class SpeechRate:\n",
    "    \"\"\"\n",
    "    Analyses speech rate, searches for fast and slow speech rate intervals.\n",
    "    \"\"\"\n",
    "    # border parameters for analysis\n",
    "    params = {\n",
    "        # size of time window to view pauses\n",
    "        \"pause_time_window\": 30,\n",
    "        # minimal noise percentage\n",
    "        \"pause_percentage\": 0.35,\n",
    "        # size of time window to speech rate\n",
    "        \"speech_rate_time_window\": 60,\n",
    "        # minimal number of words in time window for normal speech rate\n",
    "        \"speech_rate_min_word_count\": 60,\n",
    "        # maximal number of words in time window for normal speech rate\n",
    "        \"speech_rate_max_word_count\": 140,\n",
    "        # allowed pauses between words\n",
    "        \"rules\": {\n",
    "            \"word\": 0.5,\n",
    "            \"punct_mark\": 0.75,\n",
    "            \".\": 1,\n",
    "            \"?\": 5,\n",
    "            \"!\": 3\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def __init__(self, all_words_without_noise):\n",
    "        \"\"\"\n",
    "        Initialization of speech rate analysis class\n",
    "        @param all_words_without_noise: list of dicts with words and their start and end timestamps\n",
    "        \"\"\"\n",
    "        self.all_words_without_noise = all_words_without_noise\n",
    "\n",
    "    def find_pauses(self):\n",
    "        \"\"\"\n",
    "        Finds all pauses longer than allowed\n",
    "        @return: list of two-element lists with pauses timestamps\n",
    "        \"\"\"\n",
    "        rules = self.params[\"rules\"]\n",
    "        pauses = []\n",
    "        start_idx = 0\n",
    "        end_idx = 1\n",
    "        while end_idx < len(self.all_words_without_noise) - 1:\n",
    "            silence_start = self.all_words_without_noise[start_idx][\"end\"]\n",
    "            silence_end = self.all_words_without_noise[end_idx][\"start\"]\n",
    "            # detecting pause type\n",
    "            if self.all_words_without_noise[start_idx][\"text\"][-1].isalpha():\n",
    "                pause_type = rules[\"word\"]\n",
    "            elif self.all_words_without_noise[start_idx][\"text\"][-1] in rules:\n",
    "                pause_type = rules[self.all_words_without_noise[start_idx][\"text\"][-1]]\n",
    "            else:\n",
    "                pause_type = rules[\"punct_mark\"]\n",
    "            # checking with border value (depends on pause type)\n",
    "            if silence_end - silence_start > pause_type:\n",
    "                pauses.append([silence_start, silence_end])\n",
    "            start_idx = end_idx\n",
    "            end_idx += 1\n",
    "        return pauses\n",
    "\n",
    "    def find_pause_intervals(self, pauses):\n",
    "        \"\"\"\n",
    "        Searches periods with high pauses percentage with the help of floating window\n",
    "        @param pauses: pauses intervals, list of two-element lists\n",
    "        @return: list of two-element lists with pause intervals timestamps\n",
    "        \"\"\"\n",
    "        intervals = []\n",
    "        if len(pauses) == 0:\n",
    "            return intervals\n",
    "        start_idx, end_idx = 0, 0\n",
    "        # current pause length\n",
    "        summary = pauses[0][1] - pauses[0][0]\n",
    "        while end_idx < len(pauses):\n",
    "            while end_idx < len(pauses) - 1 and pauses[end_idx][1] - pauses[start_idx][0] < \\\n",
    "                    self.params[\"pause_time_window\"]:\n",
    "                end_idx += 1\n",
    "                summary += pauses[end_idx][1] - pauses[end_idx][0]\n",
    "            # break if file end is reached\n",
    "            if pauses[end_idx][1] - pauses[start_idx][0] < self.params[\"pause_time_window\"]:\n",
    "                break\n",
    "            # check if the percentage of pauses is larger than parameter\n",
    "            if summary / (pauses[end_idx][1] - pauses[start_idx][0]) > self.params[\"pause_percentage\"]:\n",
    "                # if period intersects with previous one - they are united\n",
    "                if len(intervals) > 0 and intervals[-1][-1] > pauses[start_idx][0]:\n",
    "                    intervals[-1][-1] = pauses[end_idx][1]\n",
    "                else:\n",
    "                    intervals.append([pauses[start_idx][0], pauses[end_idx][1]])\n",
    "            # delete first pause, move interval start to next word\n",
    "            summary -= pauses[start_idx][1] - pauses[start_idx][0]\n",
    "            start_idx += 1\n",
    "        return intervals\n",
    "\n",
    "    def find_incorrect_speech_rate_intervals(self):\n",
    "        \"\"\"\n",
    "        Searches intervals with too fast or slow speech rate\n",
    "        @return: two lists with two-element list each - periods with too fast or slow speech rate\n",
    "        \"\"\"\n",
    "        fast_intervals = []\n",
    "        slow_intervals = []\n",
    "        word_count = 1\n",
    "        start = self.all_words_without_noise[0][\"start\"]\n",
    "        end = self.all_words_without_noise[0][\"end\"]\n",
    "        start_idx = 0\n",
    "        end_idx = 1\n",
    "        while end_idx < len(self.all_words_without_noise):\n",
    "            # add word if time window is smaller than border value\n",
    "            if end - start < self.params[\"speech_rate_time_window\"]:\n",
    "                end = self.all_words_without_noise[end_idx][\"end\"]\n",
    "                end_idx += 1\n",
    "                word_count += 1\n",
    "            else:\n",
    "                # if word count is too small or too large - append time interval to corresponding list\n",
    "                if word_count < self.params[\"speech_rate_min_word_count\"]:\n",
    "                    # unite intervals if necessary\n",
    "                    if len(slow_intervals) > 0 and slow_intervals[-1][1] >= start:\n",
    "                        slow_intervals[-1][1] = end\n",
    "                    else:\n",
    "                        slow_intervals.append([start, end])\n",
    "                elif word_count > self.params[\"speech_rate_max_word_count\"]:\n",
    "                    # unite intervals if necessary\n",
    "                    if len(fast_intervals) > 0 and fast_intervals[-1][1] >= start:\n",
    "                        fast_intervals[-1][1] = end\n",
    "                    else:\n",
    "                        fast_intervals.append([start, end])\n",
    "                # remove first word from interval\n",
    "                start_idx += 1\n",
    "                start = self.all_words_without_noise[start_idx][\"start\"]\n",
    "                word_count -= 1\n",
    "        return slow_intervals, fast_intervals\n",
    "\n",
    "    def get_intervals(self):\n",
    "        \"\"\"\n",
    "        get slow intervals in two formats - high pauses percentage and low speech rate\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        speech_rate_results, _ = self.find_incorrect_speech_rate_intervals()\n",
    "        pauses = self.find_pauses()\n",
    "        pause_intervals = self.find_pause_intervals(pauses)\n",
    "        return speech_rate_results, pause_intervals\n",
    "\n",
    "    def unite_slow_speech_rate_intervals(self):\n",
    "        \"\"\"\n",
    "        Unites two lists of intervals: with pauses and with slow speech rate\n",
    "        @return: list of two-element lists with slow speech rate intervals timestamps\n",
    "        \"\"\"\n",
    "        speech_rate_results, _ = self.find_incorrect_speech_rate_intervals()\n",
    "        pauses = self.find_pauses()\n",
    "        pause_intervals = self.find_pause_intervals(pauses)\n",
    "        final_intervals = []\n",
    "        speech_rate_idx, pause_idx = 0, 0\n",
    "        while speech_rate_idx < len(speech_rate_results) and pause_idx < len(pause_intervals):\n",
    "            sr_start, sr_end = speech_rate_results[speech_rate_idx]\n",
    "            pause_start, pause_end = pause_intervals[pause_idx][0], pause_intervals[pause_idx][1]\n",
    "            if sr_start <= pause_start:\n",
    "                if sr_end <= pause_start:\n",
    "                    speech_rate_idx += 1\n",
    "                elif pause_start < sr_end <= pause_end:\n",
    "                    final_intervals.append([pause_start, sr_end])\n",
    "                    speech_rate_idx += 1\n",
    "                else:\n",
    "                    final_intervals.append([pause_start, pause_end])\n",
    "                    pause_idx += 1\n",
    "            elif pause_start <= sr_start <= pause_end:\n",
    "                if sr_end <= pause_end:\n",
    "                    final_intervals.append([sr_start, sr_end])\n",
    "                    speech_rate_idx += 1\n",
    "                else:\n",
    "                    final_intervals.append([sr_start, pause_end])\n",
    "                    pause_idx += 1\n",
    "            else:\n",
    "                pause_idx += 1\n",
    "        return final_intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9iQuuW8RAu60"
   },
   "outputs": [],
   "source": [
    "class SpeechProcessingSubsystem:\n",
    "    def __init__(self, path, negative_emotions_bool, analyzed_segment_len, lang):\n",
    "        \"\"\"\n",
    "        Initialization of speech processing class\n",
    "        @param path: path to video file\n",
    "        @param negative_emotions_bool: list of unwanted emotions (set by user)\n",
    "        @param analyzed_segment_len: length of file segment to analyze separately\n",
    "        \"\"\"\n",
    "        # rewrite video to audio file\n",
    "        clip = mp_editor.VideoFileClip(path)\n",
    "        audio_path = path[:path.rfind('.')] + '.wav'\n",
    "        clip.audio.write_audiofile(audio_path, logger=None)\n",
    "        self.path = audio_path\n",
    "        # fields for words and noise timestamps\n",
    "        self.cleaned_transcription = None\n",
    "        self.all_words_without_noise = None\n",
    "        self.noise = None\n",
    "        self.duration = clip.duration\n",
    "        self.analyzed_segment_len = analyzed_segment_len\n",
    "        self.negative_emotions_bool = negative_emotions_bool\n",
    "        self.lang = lang\n",
    "\n",
    "    def speech_recognition(self):\n",
    "        \"\"\"\n",
    "        Performs ASR process\n",
    "        \"\"\"\n",
    "        speech_recogniser = AutomaticSpeechRecognition(self.path, self.lang)\n",
    "        cleaned_transcription, word_arrays, correct_transcription = \\\n",
    "            speech_recogniser.get_speech_recognition()\n",
    "        # fill class params with ASR results\n",
    "        self.cleaned_transcription = cleaned_transcription\n",
    "        self.all_words_without_noise = word_arrays[0]\n",
    "        self.noise = word_arrays[1]\n",
    "\n",
    "    @staticmethod\n",
    "    def unite_intervals(intervals_1, intervals_2):\n",
    "        \"\"\"\n",
    "        Unite two time frames intervals\n",
    "        @param intervals_1: first list of intervals\n",
    "        @param intervals_2: second list of intervals\n",
    "        @return: united list of intervals\n",
    "        \"\"\"\n",
    "        final_intervals = []\n",
    "        # indexes to indexing through lists\n",
    "        first_idx, second_idx = 0, 0\n",
    "        while first_idx < len(intervals_1) and second_idx < len(intervals_2):\n",
    "            interval_1_start, interval_1_end = intervals_1[first_idx]\n",
    "            interval_2_start, interval_2_end = intervals_2[second_idx][0], intervals_2[second_idx][1]\n",
    "            # if first interval's time period is earlier\n",
    "            if interval_1_start <= interval_2_start:\n",
    "                # first interval's time period is inside second's\n",
    "                if interval_1_end <= interval_2_start:\n",
    "                    first_idx += 1\n",
    "                elif interval_2_start < interval_1_end <= interval_2_end:\n",
    "                    final_intervals.append([interval_2_start, interval_1_end])\n",
    "                    first_idx += 1\n",
    "                else:\n",
    "                    final_intervals.append([interval_2_start, interval_2_end])\n",
    "                    second_idx += 1\n",
    "            # if second interval's time period is earlier\n",
    "            elif interval_2_start <= interval_1_start <= interval_2_end:\n",
    "                if interval_1_end <= interval_2_end:\n",
    "                    final_intervals.append([interval_1_start, interval_1_end])\n",
    "                    first_idx += 1\n",
    "                else:\n",
    "                    final_intervals.append([interval_1_start, interval_2_end])\n",
    "                    second_idx += 1\n",
    "            else:\n",
    "                second_idx += 1\n",
    "        return final_intervals\n",
    "\n",
    "    def periods_to_fractions(self, intervals, length):\n",
    "        \"\"\"\n",
    "        Saves percentages of intervals per analyzed file fragment length\n",
    "        @param intervals: time intervals of any kind\n",
    "        @param length: result's list length\n",
    "        @return: list with fractions (percentages) of occurrence\n",
    "        \"\"\"\n",
    "        res = np.zeros(length)\n",
    "        for i in intervals:\n",
    "            fraction = (i[1] - i[0]) / self.analyzed_segment_len\n",
    "            idx = int(i[0] // self.analyzed_segment_len)\n",
    "            res[idx] = round(res[idx] + fraction, 3)\n",
    "        return res\n",
    "\n",
    "    def get_fraction(self, timestamps):\n",
    "        \"\"\"\n",
    "        Counts timestamps proportion of some event\n",
    "        @param timestamps: time periods of some event\n",
    "        @return: timestamps proportion of some event\n",
    "        \"\"\"\n",
    "        duration = 0\n",
    "        for time_period in timestamps:\n",
    "            duration += time_period[1] - time_period[0]\n",
    "        return duration / self.duration\n",
    "\n",
    "    def get_fractions_from_intervals(self, intervals):\n",
    "        \"\"\"\n",
    "        Transform random length intervals to N-second fractions\n",
    "        @param intervals: intervals of some event\n",
    "        @return: list of fraction per file fragment\n",
    "        \"\"\"\n",
    "        length = math.ceil(self.duration / self.analyzed_segment_len)\n",
    "        fixed_intervals = [[i * self.analyzed_segment_len, (i + 1) * self.analyzed_segment_len] for i in range(length)]\n",
    "        united_intervals = self.unite_intervals(intervals, fixed_intervals)\n",
    "        fractions = self.periods_to_fractions(united_intervals, len(fixed_intervals))\n",
    "        return fractions\n",
    "\n",
    "    def get_emotionality(self):\n",
    "        \"\"\"\n",
    "        Analyses emotionality of file\n",
    "        @return: list of lists of emotions probabilities and time period per which emotions are defined\n",
    "        \"\"\"\n",
    "        audio_emotions = AudioEmotions(self.path, self.analyzed_segment_len, self.negative_emotions_bool)\n",
    "        negative_emotions_fractions, neutral_emotion_fractions = audio_emotions.emotions_analysis()\n",
    "        return negative_emotions_fractions, neutral_emotion_fractions\n",
    "\n",
    "    def get_filler_words(self):\n",
    "        \"\"\"\n",
    "        Analyses presence of filler words\n",
    "        @return: dicts with all filler words and phrases and with most common ones\n",
    "        \"\"\"\n",
    "        filler_words = FillerWordsAndPhrases(self.cleaned_transcription, self.lang)\n",
    "        all_filler_words_dict, worst_words = filler_words.get_filler_words_final()\n",
    "        return all_filler_words_dict, worst_words\n",
    "\n",
    "    def get_speech_rate(self):\n",
    "        \"\"\"\n",
    "        Analyses speech rate of speech\n",
    "        @return: intervals with slow speech rate and their percentage of file duration\n",
    "        \"\"\"\n",
    "        speech_rate = SpeechRate(self.all_words_without_noise)\n",
    "        speech_rate_results, pause_intervals = speech_rate.get_intervals()\n",
    "        intervals = self.unite_intervals(speech_rate_results, pause_intervals)\n",
    "        fractions = self.get_fractions_from_intervals(intervals)\n",
    "        return intervals, fractions, self.get_fraction(intervals)\n",
    "\n",
    "    def get_background_noise(self):\n",
    "        \"\"\"\n",
    "        Analyses background noise presence\n",
    "        @return: intervals with high background noise and their percentage of file duration\n",
    "        \"\"\"\n",
    "        # collect high background noise intervals\n",
    "        background_noise = BackgroundNoise(self.noise)\n",
    "        high_noise_intervals = background_noise.get_high_noise_timestamps()\n",
    "        # transform to fractions for each file fragment\n",
    "        high_noise_fractions = self.get_fractions_from_intervals(high_noise_intervals)\n",
    "        high_noise_fractions = np.array(high_noise_fractions)\n",
    "\n",
    "        # collect STOI indexes\n",
    "        intelligibility = Intelligibility(self.path, self.all_words_without_noise, self.noise,\n",
    "                                          self.analyzed_segment_len)\n",
    "        indexes = intelligibility.stoi_index()\n",
    "        # transform to fractions for each file fragment\n",
    "        fractions = (high_noise_fractions + 1 - indexes) / 2\n",
    "        return high_noise_intervals, fractions, self.get_fraction(high_noise_intervals)\n",
    "\n",
    "    def get_intelligibility(self):\n",
    "        \"\"\"\n",
    "        Analyses intelligibility of speech\n",
    "        @return: approximate intelligibility per file fragment and summary intelligibility\n",
    "        \"\"\"\n",
    "        # collect basic intelligibility measures\n",
    "        intelligibility = Intelligibility(self.path, self.all_words_without_noise, self.noise,\n",
    "                                          self.analyzed_segment_len)\n",
    "        indexes, fast_intervals, noisy_intervals = intelligibility.get_intelligibility_features()\n",
    "        # transform to fractions on whole file\n",
    "        fast_fraction = self.get_fraction(fast_intervals)\n",
    "        noisy_fraction = self.get_fraction(noisy_intervals)\n",
    "        index_fraction = np.average(indexes)\n",
    "        # transform to fractions per file fragment\n",
    "        noisy_fractions = np.array(self.get_fractions_from_intervals(noisy_intervals))\n",
    "        fast_fractions = np.array(self.get_fractions_from_intervals(fast_intervals))\n",
    "\n",
    "        # count average\n",
    "        negative_fractions = (2 * noisy_fractions + fast_fractions + 2 * (1 - indexes)) / 5\n",
    "        negative_fraction = (fast_fraction + 2 * noisy_fraction + 2 * (1 - index_fraction)) / 5\n",
    "        return negative_fractions, negative_fraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPd9BdumEpRe"
   },
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "biH6QlukMPXz"
   },
   "outputs": [],
   "source": [
    "CONSTANTS = {\n",
    "    \"clean_speech\": (0.3, 0.8),\n",
    "    \"speech_rate\": (0.3, 0.6),\n",
    "    \"background_noise\": (0.3, 0.6),\n",
    "    \"intelligibility\": (0.3, 0.6),\n",
    "    \"clothes\": (0.5, 1),\n",
    "    \"gestures\": (0, 1),\n",
    "    \"angle\": (0.3, 0.6),\n",
    "    \"glances\": (0.6, 1),\n",
    "    \"emotionality\": (0.3, 0.6),\n",
    "    \"neutral_emotionality_official\": (0.2, 0.6),\n",
    "    \"neutral_emotionality_nonofficial\": (0.2, 0.6),\n",
    "}\n",
    "\n",
    "ORDER = [\n",
    "    \"background_noise\",\n",
    "    \"speech_rate\",\n",
    "    \"emotionality\",\n",
    "    \"intelligibility\",\n",
    "    \"gestures\",\n",
    "    \"glances\"\n",
    "]\n",
    "\n",
    "DRAW_VALUES = {\n",
    "    \"speech_rate\": {\n",
    "        0: \"Оптимальный темп речи\",\n",
    "        1: \"Немного медленный темп речи\",\n",
    "        2: \"Слишком медленный темп речи\"\n",
    "    },\n",
    "    \"background_noise\": {\n",
    "        0: \"Нет фонового шума\",\n",
    "        1: \"Небольшой фоновый шум\",\n",
    "        2: \"Сильный фоновый шум\"\n",
    "    },\n",
    "    \"intelligibility\": {\n",
    "        0: \"Речь совсем неразборчива\",\n",
    "        1: \"Речь немного неразборчива\",\n",
    "        2: \"Речь полностью разборчива\",\n",
    "    },\n",
    "    \"gestures\": {\n",
    "        0: 'Неактивная жестикуляция',\n",
    "        1: 'Оптимальная жестикуляция',\n",
    "        2: 'Активная жестикуляция',\n",
    "    },\n",
    "    \"glances\": {\n",
    "        0: None,\n",
    "        1: 'Вы часто отводите взгляд'\n",
    "    },\n",
    "    \"emotionality\": {\n",
    "        0: \"Преимущественно желаемые эмоции\",\n",
    "        1: \"Не полностью желаемые эмоции\",\n",
    "        2: \"Не желаемые эмоции\",\n",
    "    },\n",
    "    \"lightning\": {\n",
    "        0: 'Слишком темное освещение',\n",
    "        1: 'Оптимальное освещение',\n",
    "        2: 'Слишком яркое освещение',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KpYKU1LHEq3F"
   },
   "outputs": [],
   "source": [
    "class FileProcessingSystem:\n",
    "    \"\"\"\n",
    "    Class for file analysis\n",
    "    \"\"\"\n",
    "    def __init__(self, file, flags, negative_emotions_bool, preferred_gestures_bool, analyzed_segment_len, lang):\n",
    "        \"\"\"\n",
    "        Initializing of file and its params\n",
    "        @param file: FileInfo instance to analyze\n",
    "        @param analyzed_segment_len: length of one file fragment to analyze\n",
    "        @param language_flag: text language flag (for recommendations and statistics)\n",
    "        \"\"\"\n",
    "        self.file_path = file\n",
    "        self.analyzed_segment_len = analyzed_segment_len\n",
    "        self.flags = flags\n",
    "        emotions = [\"Happiness\", \"Anger\", \"Disgust\", \"Neutral\", \"Sadness\", \"Surprise\"]\n",
    "        negative_emotions = []\n",
    "        for i, flag in enumerate(negative_emotions_bool):\n",
    "            if flag:\n",
    "                negative_emotions.append(emotions[i])\n",
    "        self.negative_emotions_bool = negative_emotions_bool\n",
    "        self.preferred_gestures_bool = preferred_gestures_bool\n",
    "        self.timestamps = {}\n",
    "        self.computer_vision = VideoSubsystem(self.file_path, negative_emotions, emotions=flags[\"emotionality\"],\n",
    "                                              gesticulation=flags[\"gestures\"], angle=flags[\"angle\"],\n",
    "                                              gaze=flags[\"glances\"], clothes=flags[\"clothes\"])\n",
    "        self.computer_vision.process_video(duration=analyzed_segment_len)\n",
    "        self.speech_processing = SpeechProcessingSubsystem(self.file_path, negative_emotions_bool,\n",
    "                                                           analyzed_segment_len=analyzed_segment_len, lang=lang)\n",
    "\n",
    "\n",
    "    def save_timestamps_to_db(self, timestamps, type_choice):\n",
    "        \"\"\"\n",
    "        Saves timestamps of low speech rate or high background noise to database\n",
    "        @param timestamps: periods to be saved\n",
    "        @param type_choice: 0 for background noise, 1 for speech rate\n",
    "        \"\"\"\n",
    "        periods = []\n",
    "        for time_period in timestamps:\n",
    "            start_seconds, end_seconds = round(time_period[0]), round(time_period[1])\n",
    "            # transform seconds to time type\n",
    "            start = time(hour=start_seconds // 3600, minute=start_seconds // 60, second=start_seconds % 60)\n",
    "            end = time(hour=end_seconds // 3600, minute=end_seconds // 60, second=end_seconds % 60)\n",
    "            periods.append((start, end))\n",
    "        return periods\n",
    "\n",
    "    def get_transcription(self):\n",
    "        \"\"\"\n",
    "        Translates and saves file transcription\n",
    "        \"\"\"\n",
    "        self.speech_processing.speech_recognition()\n",
    "        return self.speech_processing.cleaned_transcription\n",
    "\n",
    "    def get_emotionality(self):\n",
    "        \"\"\"\n",
    "        Gets emotionality from audio and video subsystems, unites them and saves neutral emotion fraction\n",
    "        \"\"\"\n",
    "        video_emotions = self.computer_vision.get_inappropriate_emotion_percentage()\n",
    "        video_neutral_emotions = self.computer_vision.get_emotions()\n",
    "\n",
    "        try:\n",
    "            audio_emotions, audio_neutral_emotions = self.speech_processing.get_emotionality()\n",
    "        except Exception as e:\n",
    "            audio_emotions = self.computer_vision.get_inappropriate_emotion_percentage()\n",
    "            audio_neutral_emotions = self.computer_vision.get_emotions()\n",
    "        audio_emotions = np.array(audio_emotions)\n",
    "        video_emotions = np.array(video_emotions)\n",
    "        incorrect_emotions_percentage = (2 * video_emotions + audio_emotions) / 3\n",
    "        incorrect_emotions_percentage = np.round(np.array(incorrect_emotions_percentage), 3)\n",
    "        emotions_fraction = round(np.sum(incorrect_emotions_percentage) / len(incorrect_emotions_percentage), 3)\n",
    "\n",
    "        neutral_emotions = (np.array(video_neutral_emotions) + np.array(audio_neutral_emotions)) / 2\n",
    "        neutral_emotions_fraction = round(np.sum(neutral_emotions) / len(neutral_emotions), 3)\n",
    "        self.timestamps[\"emotionality\"] = incorrect_emotions_percentage\n",
    "        # доля нейтральных эмоций во всем видео, доля нежелательных эмоций во всем видео, доли нежелательных эмоций в каждом отрезке\n",
    "        return neutral_emotions_fraction, emotions_fraction, incorrect_emotions_percentage\n",
    "\n",
    "    def get_filler_words(self):\n",
    "        \"\"\"\n",
    "        Gets filler words and phrases, saves them and their count per minute\n",
    "        \"\"\"\n",
    "        all_filler_words, worst_filler_words = self.speech_processing.get_filler_words()\n",
    "\n",
    "        overall_count = sum(list(all_filler_words.values()))\n",
    "        words_per_minute_percentage = round((overall_count / (self.speech_processing.duration / 60)) / 10, 5)\n",
    "        # доля слов-паразитов во всем видео, все слова-паразиты и их встречаемость, самые частые слова-паразиты и их встречаемость\n",
    "        return words_per_minute_percentage, all_filler_words, worst_filler_words\n",
    "\n",
    "    def get_speech_rate(self):\n",
    "        \"\"\"\n",
    "        Gets and saves intervals with slow speech rate and their percentage\n",
    "        \"\"\"\n",
    "        intervals, fractions, final_fraction = self.speech_processing.get_speech_rate()\n",
    "        self.timestamps[\"speech_rate\"] = fractions\n",
    "        # доля с низким темпом речи во всем видео, доли с низким темпом речи в каждом отрезке, интервалы с низким темпом речи\n",
    "        return final_fraction, fractions, intervals\n",
    "\n",
    "    def get_background_noise(self):\n",
    "        \"\"\"\n",
    "        Gets and saves intervals with high background noise and their percentage\n",
    "        \"\"\"\n",
    "        intervals, fractions, final_fraction = self.speech_processing.get_background_noise()\n",
    "        self.timestamps[\"background_noise\"] = fractions\n",
    "        # доля с высоким фоновым шумом во всем видео, доли с высоким фоновым шумом в каждом отрезке, интервалы с высоким фоновым шумом\n",
    "        return final_fraction, fractions, intervals\n",
    "\n",
    "    def get_intelligibility(self):\n",
    "        \"\"\"\n",
    "        Gets and saves intelligibility estimation\n",
    "        \"\"\"\n",
    "        negative_fractions, negative_index = self.speech_processing.get_intelligibility()\n",
    "        fractions = np.round(1 - negative_fractions, 3)\n",
    "        self.timestamps[\"intelligibility\"] = fractions\n",
    "        # разборчивость речи во всем видео, разборчивость речи в каждом отрезке\n",
    "        return 1 - negative_index, fractions\n",
    "\n",
    "    def get_incorrect_angle(self):\n",
    "        \"\"\"\n",
    "        Gets and saves incorrect angle percentage\n",
    "        \"\"\"\n",
    "        incorrect_angle_fractions = self.computer_vision.get_angle()\n",
    "        incorrect_angle_fractions = np.round(np.array(incorrect_angle_fractions), 3)\n",
    "        incorrect_angle = round(np.sum(incorrect_angle_fractions) / len(incorrect_angle_fractions), 3)\n",
    "        # доля некорректного ракурса во всем видео, доля некорректного ракурса в каждом отрезке\n",
    "        return incorrect_angle, incorrect_angle_fractions\n",
    "\n",
    "    def get_incorrect_glances(self):\n",
    "        \"\"\"\n",
    "        Gets and saves incorrect glances percentage\n",
    "        \"\"\"\n",
    "        incorrect_glance_fractions = self.computer_vision.get_gaze()\n",
    "        incorrect_glance_fractions = np.round(np.array(incorrect_glance_fractions), 3)\n",
    "        incorrect_glance = round(np.sum(incorrect_glance_fractions) / len(incorrect_glance_fractions), 3)\n",
    "        self.timestamps[\"glances\"] = incorrect_glance_fractions\n",
    "        # доля некорректного направления взгляда во всем видео, доля некорректного направления взгляда в каждом отрезке\n",
    "        return incorrect_glance, incorrect_glance_fractions\n",
    "\n",
    "    def get_gestures(self):\n",
    "        \"\"\"\n",
    "        Gets and saves gesticulation level\n",
    "        \"\"\"\n",
    "        gestures = self.computer_vision.get_gestures()\n",
    "        gestures = np.round(np.array(gestures), 3)\n",
    "        final_gesture_fraction = round(np.sum(gestures) / len(gestures), 3)\n",
    "        self.timestamps[\"gestures\"] = gestures\n",
    "        # активность жестикуляции во всем видео, активность жестикуляции в каждом отрезке\n",
    "        return final_gesture_fraction, gestures\n",
    "\n",
    "    def get_clothes(self):\n",
    "        \"\"\"\n",
    "        Gets and saves clothes suitability\n",
    "        \"\"\"\n",
    "        clothes = self.computer_vision.get_clothes_estimation()\n",
    "        # корректность одежды (True - одежда подходит)\n",
    "        return clothes\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Draw analysis result signatures on video file\n",
    "        \"\"\"\n",
    "        print(self.timestamps)\n",
    "        # indexes of best values for each parameter\n",
    "        optimal_indexes = {\n",
    "            \"background_noise\": 0,\n",
    "            \"speech_rate\": 0,\n",
    "            \"emotionality\": 0,\n",
    "            \"intelligibility\": 2,\n",
    "            \"gestures\": self.preferred_gestures_bool,\n",
    "            \"glances\": 0,\n",
    "            \"lightning\": 0,\n",
    "        }\n",
    "        lst = ORDER\n",
    "        # texts to put into file\n",
    "        text_values = []\n",
    "        # boolean values (True - optimal) for text color\n",
    "        boolean_flags = []\n",
    "        for period_index, name in enumerate(lst):\n",
    "            if name in self.timestamps:\n",
    "                text_values.append([])\n",
    "                boolean_flags.append([])\n",
    "                # get grades for parameter for each file fragment\n",
    "                res = self.timestamps[name]\n",
    "                print(name, res)\n",
    "                # transform grade into text\n",
    "                for value in res:\n",
    "                    text_idx = 0\n",
    "                    if value > CONSTANTS[name][1]:\n",
    "                        text_idx = 2\n",
    "                    elif value > CONSTANTS[name][0]:\n",
    "                        text_idx = 1\n",
    "                    text = DRAW_VALUES[name][text_idx]\n",
    "                    text_values[-1].append(text)\n",
    "                    # append text color\n",
    "                    if name == \"gestures\":\n",
    "                        boolean_flags[-1].append(text_idx in optimal_indexes[name])\n",
    "                    else:\n",
    "                        boolean_flags[-1].append(text_idx == optimal_indexes[name])\n",
    "\n",
    "        # append values on lightning if possible\n",
    "        lightning_numbers = self.computer_vision.get_lightning()\n",
    "        if len(lightning_numbers) > 0:\n",
    "            text_values.append([])\n",
    "            boolean_flags.append([])\n",
    "            for val in lightning_numbers:\n",
    "                text_values[-1].append(DRAW_VALUES[\"lightning\"][val])\n",
    "                boolean_flags[-1].append(val == 1)\n",
    "\n",
    "        draw_res = DrawResults(self.file_path, dist=self.analyzed_segment_len)\n",
    "        # path for temporary file\n",
    "        temp_path = self.file_path[:self.file_path.rfind('.')] + '_temp.' + \\\n",
    "                       self.file_path[self.file_path.rfind('.')+1:]\n",
    "        # file is saved without noise\n",
    "        print(text_values)\n",
    "        print(boolean_flags)\n",
    "        draw_res.draw(temp_path, text_values, boolean_flags,\n",
    "                      self.computer_vision.get_angle_len(), self.computer_vision.get_incorrect_angle_ind())\n",
    "\n",
    "        # unite video and audio\n",
    "        output = mp_editor.VideoFileClip(temp_path)\n",
    "        painted_path = self.file_path[:self.file_path.rfind('.')] + '_painted.' + self.file_path[self.file_path.rfind('.')+1:]\n",
    "        final_duration = output.duration\n",
    "        output_audio = mp_editor.VideoFileClip(self.file_path).audio.subclip(0, final_duration)\n",
    "        output.audio = output_audio\n",
    "        output.write_videofile(painted_path)\n",
    "        return painted_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1kADWpP-GxmL"
   },
   "outputs": [],
   "source": [
    "flags = {\"emotionality\": True, \"gestures\": True, \"angle\": True, \"glances\": True, \"clothes\": True}\n",
    "negative_emotions = [False, True, True, False, False, False] # Happiness, Anger, Disgust, Neutral, Sadness, Surprise\n",
    "preferred_gestures = [True, True, False] # inactive, medium, active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation in Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdUiHA6nStg4",
    "outputId": "31ec89e8-441e-4e72-ae76-bdc0c2cc74b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                     | 0/6 [00:00<?, ?it/s]I0000 00:00:1745618967.169847 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618967.295472 6246214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618967.329427 6246214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618967.350996 6246221 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "I0000 00:00:1745618967.623963 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618967.751983 6246246 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618967.786578 6246246 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618968.189443 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618968.311603 6246267 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618968.346737 6246267 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618968.644439 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618968.766792 6246286 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618968.800936 6246286 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618969.100075 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618969.224514 6246306 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618969.258035 6246306 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618969.565575 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618969.689281 6246329 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618969.723029 6246338 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618970.018015 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618970.142037 6246346 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618970.175190 6246346 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618970.468935 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618970.592546 6246363 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618970.625687 6246372 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618970.934231 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618971.060728 6246408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618971.099316 6246408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618971.436020 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618971.565422 6246425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618971.600646 6246425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618972.095262 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618972.257033 6246450 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618972.307460 6246450 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745618987.868891 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745618987.870051 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745618987.879825 6246707 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745618987.898402 6246707 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619002.006175 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619002.139028 6246911 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619002.172874 6246920 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 17%|████████████████████████████████████▊                                                                                                                                                                                        | 1/6 [00:38<03:11, 38.34s/it]I0000 00:00:1745619005.533953 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619005.658326 6246975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619005.695721 6246975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619006.000888 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619006.128157 6247000 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619006.163706 6247000 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619006.463604 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619006.588488 6247019 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619006.622017 6247026 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619006.929271 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619007.053952 6247041 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619007.090372 6247041 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619007.398722 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619007.522059 6247061 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619007.557623 6247061 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619007.851349 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619007.976420 6247090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619008.012033 6247090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619008.303070 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619008.426762 6247113 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619008.461043 6247113 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619008.746685 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619008.869081 6247139 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619008.904718 6247149 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619009.193612 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619009.319182 6247158 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619009.354063 6247164 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619009.645194 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619009.769576 6247179 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619009.804914 6247179 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619010.092112 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619010.308033 6247196 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619010.350397 6247196 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619024.570896 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619024.571806 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619024.579988 6247415 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619024.597827 6247415 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 2/6 [01:09<02:15, 33.96s/it]I0000 00:00:1745619037.011898 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619037.151550 6247634 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619037.201780 6247634 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619037.494170 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619037.624397 6247658 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619037.659889 6247665 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619037.999234 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619038.126219 6247691 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619038.162666 6247697 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619038.466405 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619038.594329 6247708 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619038.631980 6247708 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619038.998907 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619039.127646 6247734 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619039.164682 6247734 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619039.481192 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619039.710442 6247748 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619039.793883 6247757 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619040.093081 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619040.219616 6247773 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619040.253169 6247773 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619040.584962 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619040.713178 6247793 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619040.749004 6247801 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619041.069627 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619041.207343 6247818 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619041.249676 6247818 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619041.588560 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619041.722225 6247831 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619041.769694 6247831 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619042.106902 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619042.255606 6247861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619042.296539 6247861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619058.734103 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619058.735062 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619058.744087 6248113 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619058.763653 6248127 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                              | 3/6 [01:43<01:42, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619070.416253 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619070.556032 6248364 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619070.591275 6248371 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619070.877150 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619071.000443 6248401 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619071.034721 6248401 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619071.329430 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619071.463942 6248411 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619071.511133 6248411 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619071.907728 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619072.062930 6248437 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619072.112093 6248447 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619072.521650 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619072.656261 6248462 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619072.706133 6248469 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619073.251209 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619073.384644 6248488 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619073.426753 6248496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619073.799773 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619073.940792 6248512 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619073.986763 6248512 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619074.506940 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619074.659097 6248534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619074.704637 6248534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619075.150348 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619075.310518 6248567 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619075.388573 6248569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619075.823827 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619075.959371 6248621 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619075.998237 6248621 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619076.503268 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619076.647297 6248639 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619076.683337 6248640 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619091.510338 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619091.511002 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619091.520342 6248844 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619091.543590 6248856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 4/6 [02:12<01:04, 32.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619098.959650 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619099.129998 6249002 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619099.166094 6249013 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619099.482322 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619099.610681 6249021 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619099.647540 6249030 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619099.959243 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619100.094489 6249061 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619100.155224 6249069 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619100.709633 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619100.848537 6249103 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619100.892827 6249103 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619101.321429 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619101.448127 6249120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619101.483142 6249120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619101.784761 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619101.911539 6249142 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619101.950486 6249142 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619102.328782 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619102.468614 6249167 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619102.505914 6249177 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619102.874893 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619103.003875 6249194 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619103.043390 6249194 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619103.407575 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619103.538633 6249210 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619103.580621 6249218 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619103.950401 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619104.079878 6249234 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619104.122023 6249234 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619104.687960 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619104.853922 6249262 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619104.907190 6249275 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619121.529576 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619121.530392 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619121.541916 6249525 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619121.561954 6249539 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                    | 5/6 [02:40<00:30, 30.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619126.157986 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619126.317507 6249620 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619126.364608 6249620 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619126.742191 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619126.890793 6249645 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619126.936540 6249640 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619127.285919 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619127.434892 6249659 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619127.474766 6249659 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619127.822119 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619127.971478 6249687 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619128.010602 6249695 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619128.353865 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619128.503141 6249710 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619128.543567 6249719 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619128.891374 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619129.046911 6249742 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619129.086862 6249742 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619129.427983 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619129.587032 6249758 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619129.627894 6249766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619129.708250 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619129.862081 6249781 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619129.908277 6249781 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619139.917059 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619139.917938 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619139.928078 6249940 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619139.947074 6249950 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:57<00:00, 29.59s/it]\n"
     ]
    }
   ],
   "source": [
    "processing = FileProcessingSystem(\"short_rus.mp4\", flags, negative_emotions, preferred_gestures, 10, \"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "vi1QA2enK_XU",
    "outputId": "7a2c07bd-36f2-4241-98e7-3b0a1467430c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5623/5623 [05:08<00:00, 18.25frames/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'привет друзья это успеть за секунд и сергей коростелев сегодня я расскажу что такое пич или техника в лифте представьте себе что вы едете в лифте с биллом гейтсом и вам нужно быстро рассказать о своем бизнесе итак пич первое это название продукта или проекта второе категория продукта то есть что это вообще такое третье целевая аудитория для кого этот проект четвертое основная задача какие цели он преследует и конечно же пятое это его уникальность в чем ваш проект уникален ну к примеру расскажу вот про наш быстро сервис мы сейчас делаем сервис услуги мечты услуги мечты это онлайн сервис по предоставлению бытовых услуг для мам и пап которые позволили заказать множество услуг в одном месте применяя высочайшие стандарты обслуживания и технологии освобождая людям время для реализации мечты и желаний надеюсь я успел'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_transcription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LG2OBVj5LDjL",
    "outputId": "aa604af6-5628-44e7-968a-d8d59c6a8417"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.649, 0.283, array([0.7, 0.5, 0.3, 0.2, 0. , 0. ]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_emotionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-ndjKVzLJ8Z",
    "outputId": "4e53884d-b8d2-4839-883e-0c666b82d0dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96034,\n",
       " {'в лифте': 2,\n",
       "  'услуги мечты': 2,\n",
       "  'вообще': 1,\n",
       "  'конечно': 1,\n",
       "  'ну': 1,\n",
       "  'вот': 1,\n",
       "  'то есть': 1},\n",
       " {'в лифте': 2, 'услуги мечты': 2})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_filler_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvNf1uw1LMFm",
    "outputId": "4361a483-3442-494e-c438-4c089d17411c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([0., 0., 0., 0., 0., 0.]), [])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_speech_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwaDnGwTLT9R",
    "outputId": "0429f3e8-37bc-4e66-a629-b3904f3f84b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([0.045 , 0.0375, 0.0405, 0.043 , 0.053 , 0.042 ]), [])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_background_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJGLKRZcLVsu",
    "outputId": "98f4a34e-de4e-4577-f37c-c6725fab385e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9652000000000001, array([0.964, 0.97 , 0.968, 0.966, 0.958, 0.966]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_intelligibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVlShanfLV6j",
    "outputId": "e73d7a9f-1479-49d4-b85b-9cb9bbb3b36f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.128, array([0.347, 0.223, 0.197, 0.   , 0.   , 0.   ]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_incorrect_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPq4LHc4LWGR",
    "outputId": "b33dc072-77ea-49d7-f7c9-f58415c4bb78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.633, array([0.378, 0.477, 0.557, 0.384, 1.   , 1.   ]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_incorrect_glances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69_yaU1zLWgz",
    "outputId": "79b42430-bb5d-4029-ead7-dade5e13d27f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, array([2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_gestures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jDLDPH1LWsL",
    "outputId": "3cf39a69-e325-4d70-a5a4-4cd36003a9c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_clothes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdwxJIdwXXv1",
    "outputId": "bb7134a1-e0b6-4a9a-d3bf-83d46fbecbaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotionality': array([0.7, 0.5, 0.3, 0.2, 0. , 0. ]), 'speech_rate': array([0., 0., 0., 0., 0., 0.]), 'background_noise': array([0.045 , 0.0375, 0.0405, 0.043 , 0.053 , 0.042 ]), 'intelligibility': array([0.964, 0.97 , 0.968, 0.966, 0.958, 0.966]), 'glances': array([0.378, 0.477, 0.557, 0.384, 1.   , 1.   ]), 'gestures': array([2, 2, 2, 2, 2, 2])}\n",
      "background_noise [0.045  0.0375 0.0405 0.043  0.053  0.042 ]\n",
      "speech_rate [0. 0. 0. 0. 0. 0.]\n",
      "emotionality [0.7 0.5 0.3 0.2 0.  0. ]\n",
      "intelligibility [0.964 0.97  0.968 0.966 0.958 0.966]\n",
      "gestures [2 2 2 2 2 2]\n",
      "glances [0.378 0.477 0.557 0.384 1.    1.   ]\n",
      "[['Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума'], ['Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи'], ['Не желаемые эмоции', 'Не полностью желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции'], ['Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива'], ['Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция'], [None, None, None, None, 'Вы часто отводите взгляд', 'Вы часто отводите взгляд'], ['Оптимальное освещение', 'Оптимальное освещение', 'Оптимальное освещение', 'Оптимальное освещение', 'Оптимальное освещение', 'Оптимальное освещение']]\n",
      "[[True, True, True, True, True, True], [True, True, True, True, True, True], [False, False, True, True, True, True], [True, True, True, True, True, True], [False, False, False, False, False, False], [True, True, True, True, False, False], [True, True, True, True, True, True]]\n",
      "Moviepy - Building video short_rus_painted.mp4.\n",
      "MoviePy - Writing audio in short_rus_paintedTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video short_rus_painted.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready short_rus_painted.mp4\n"
     ]
    }
   ],
   "source": [
    "painted_path = processing.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "Y2TggR_cuXa8",
    "outputId": "3d40f481-d230-4f0f-fbc5-330166d6e875"
   },
   "outputs": [],
   "source": [
    "video_path = painted_path\n",
    "video_clip = VideoFileClip(video_path)\n",
    "#video_clip.ipython_display(width=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdUiHA6nStg4",
    "outputId": "31ec89e8-441e-4e72-ae76-bdc0c2cc74b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                     | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619637.024971 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619637.311545 6258756 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619637.390799 6258766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619637.664829 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619637.943243 6258784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619638.018881 6258784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619638.338042 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619638.619600 6258802 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619638.709241 6258802 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619639.143017 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619639.435201 6258835 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619639.512833 6258846 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619639.953261 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619640.243274 6258861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619640.320291 6258869 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619640.597614 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619640.885976 6258880 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619640.961832 6258889 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619641.173244 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619641.459715 6258905 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619641.543080 6258914 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619641.812331 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619642.101573 6258930 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619642.178525 6258930 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619642.492181 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619642.808212 6258958 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619642.897447 6258967 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619643.247546 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619643.551040 6258983 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619643.633643 6258983 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619643.926164 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619644.228637 6259008 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619644.411965 6259008 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619657.632013 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619657.633582 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619657.652602 6259221 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619657.689445 6259220 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619666.823902 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619667.090997 6259366 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619667.169446 6259366 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 11%|████████████████████████▌                                                                                                                                                                                                    | 1/9 [00:34<04:32, 34.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619669.651751 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619669.924197 6259419 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619670.002836 6259419 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619670.387634 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619670.667577 6259445 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619670.739963 6259453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619670.935892 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619671.204064 6259476 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619671.275345 6259476 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619671.542488 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619671.797969 6259493 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619671.866034 6259493 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619672.051359 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619672.310052 6259519 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619672.390320 6259532 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619672.654903 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619672.925240 6259541 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619673.001223 6259541 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619673.253842 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619673.513957 6259562 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619673.581178 6259569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619673.949133 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619674.219923 6259588 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619674.294559 6259588 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619674.712601 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619674.968614 6259625 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619675.035472 6259632 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619675.316983 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619675.583865 6259642 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619675.666519 6259649 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619676.077396 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619676.343678 6259670 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619676.425695 6259670 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619687.419729 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619687.421051 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619687.437559 6259832 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619687.468989 6259830 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 22%|█████████████████████████████████████████████████                                                                                                                                                                            | 2/9 [00:55<03:07, 26.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619691.152542 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619691.374545 6259907 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619691.434358 6259907 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619691.624513 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619691.848459 6259925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619691.910186 6259925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619692.210366 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619692.436977 6259948 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619692.498387 6259948 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619692.922964 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619693.148308 6259974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619693.214187 6259980 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619693.383214 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619693.612083 6259991 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619693.678722 6260000 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619693.906636 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619694.135582 6260015 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619694.197797 6260024 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619694.359524 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619694.589590 6260040 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619694.651025 6260047 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619694.919382 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619695.180254 6260084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619695.244847 6260084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619695.520226 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619695.747955 6260107 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619695.813034 6260116 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619695.969730 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619696.198964 6260130 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619696.262276 6260130 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619696.459886 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619696.691320 6260147 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619696.753452 6260147 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619706.366018 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619706.367294 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619706.384437 6260340 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619706.423633 6260353 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 3/9 [01:14<02:19, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619710.447392 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619710.653588 6260417 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619710.712671 6260417 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619710.905535 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619711.110906 6260443 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619711.168423 6260443 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619711.303981 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619711.517059 6260459 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619711.572526 6260468 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619711.756168 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619711.963413 6260483 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619712.022583 6260491 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619712.242214 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619712.456071 6260499 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619712.515644 6260508 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619712.802423 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619713.019837 6260526 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619713.085609 6260534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619713.235487 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619713.450808 6260545 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619713.514899 6260545 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619713.740215 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619713.955448 6260568 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619714.014327 6260577 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619714.205535 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619714.417666 6260586 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619714.473704 6260586 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619714.668960 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619714.878627 6260607 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619714.935143 6260607 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619715.169611 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619715.390298 6260636 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619715.457531 6260646 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619724.098898 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619724.099901 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619724.113271 6260774 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619724.139513 6260784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                          | 4/9 [01:33<01:47, 21.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619728.969638 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619729.145643 6260883 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619729.195820 6260883 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619729.401571 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619729.584107 6260900 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619729.632206 6260900 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619729.833439 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619730.023648 6260926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619730.072185 6260926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619730.224494 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619730.409325 6260941 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619730.456848 6260941 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619730.649898 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619730.828398 6260958 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619730.879893 6260958 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619731.075594 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619731.253807 6260984 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619731.301590 6260993 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619731.421073 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619731.600523 6261002 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619731.760265 6261002 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619731.960493 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619732.150986 6261025 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619732.201930 6261025 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619732.391934 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619732.580326 6261043 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619732.633597 6261050 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619732.837941 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619733.021516 6261064 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619733.068720 6261073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619733.275621 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619733.470347 6261084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619733.524236 6261084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619741.262017 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619741.263201 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619741.273916 6261201 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619741.296883 6261201 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                  | 5/9 [01:49<01:18, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619744.962462 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619745.138743 6261261 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619745.202049 6261261 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619745.327537 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619745.503374 6261281 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619745.558298 6261285 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619745.753059 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619745.927529 6261303 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619745.974084 6261303 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619746.104962 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619746.274635 6261332 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619746.383272 6261332 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619746.601964 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619746.777511 6261349 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619746.834907 6261359 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619747.030682 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619747.202303 6261372 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619747.255260 6261372 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619747.448783 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619747.637483 6261403 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619747.698732 6261408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619747.816227 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619747.986261 6261473 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619748.049607 6261483 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619748.220368 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619748.387158 6261498 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619748.432904 6261498 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619748.573610 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619748.741246 6261513 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619748.790941 6261522 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619748.902691 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619749.083345 6261540 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619749.132307 6261540 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619756.820995 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619756.822417 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619756.834044 6261680 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619756.858421 6261691 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 6/9 [02:05<00:54, 18.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619760.927226 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619761.099431 6261751 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619761.150869 6261758 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619761.267341 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619761.433082 6261766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619761.478621 6261766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619761.634610 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619761.802873 6261787 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619761.849853 6261787 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619762.025031 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619762.192654 6261806 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619762.236968 6261806 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619762.404842 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619762.574710 6261823 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619762.618150 6261823 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619762.735576 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619762.911859 6261841 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619762.960313 6261851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619763.177121 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619763.347650 6261864 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619763.400362 6261864 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619763.529982 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619763.868957 6261883 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619763.923747 6261891 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619764.051121 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619764.232071 6261904 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619764.287903 6261912 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619764.836751 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619765.030314 6261933 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619765.158636 6261933 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619765.344979 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619765.543066 6261957 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619765.604206 6261957 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619773.871368 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619773.872812 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619773.886327 6262091 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619773.910461 6262092 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 7/9 [02:23<00:36, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619778.582186 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619778.758399 6262155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619778.827663 6262155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619778.950998 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619779.134123 6262182 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619779.181910 6262182 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619779.303365 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619779.483756 6262200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619779.532425 6262200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619779.649820 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619779.829862 6262216 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619779.880631 6262216 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619780.082983 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619780.264735 6262249 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619780.313382 6262249 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619780.435298 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619780.616580 6262277 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619780.666467 6262277 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619780.842050 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619781.134829 6262297 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619781.182661 6262297 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619781.305265 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619781.486153 6262315 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619781.611148 6262315 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619781.804971 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619782.001444 6262337 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619782.079748 6262347 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619782.205182 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619782.388207 6262355 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619782.435015 6262355 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619782.559110 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619782.756909 6262370 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619782.811006 6262381 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619790.844428 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619790.845841 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619790.858864 6262509 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619790.883153 6262509 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 8/9 [02:40<00:17, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745619795.593546 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619795.783326 6262588 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619795.865136 6262588 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619796.001204 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619796.187079 6262615 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619796.237713 6262615 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619796.367863 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619796.557692 6262630 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619796.610758 6262640 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619796.772291 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619796.960327 6262650 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619797.013889 6262650 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619797.152283 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619797.337388 6262670 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619797.391156 6262670 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619797.583460 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619797.765280 6262691 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619797.817743 6262691 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619798.004452 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619798.187065 6262715 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619798.236202 6262723 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619798.428577 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619798.605493 6262744 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619798.655162 6262753 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619798.832414 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619799.011936 6262774 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619799.059394 6262780 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619799.217405 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619799.397452 6262788 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619799.446916 6262788 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619799.496705 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619799.684966 6262804 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619799.737637 6262804 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1745619807.183053 6245543 gl_context.cc:369] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "W0000 00:00:1745619807.185593 6245543 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1745619807.200323 6262921 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745619807.234721 6262921 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [02:56<00:00, 19.64s/it]\n"
     ]
    }
   ],
   "source": [
    "processing = FileProcessingSystem(\"short_eng.mp4\", flags, negative_emotions, preferred_gestures, 10, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "vi1QA2enK_XU",
    "outputId": "7a2c07bd-36f2-4241-98e7-3b0a1467430c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8944/8944 [09:12<00:00, 16.17frames/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my fellow americans it has been the honor of my life to serve you i wont stop in fact i will be right there with you as a citizen for all my remaining days but for now whether you are young or whether youre young at heart i do have one final ask of you as your president the same thing i asked when you took a chance on me eight years ago i am asking you to believe not in my ability to bring about change but in yours i am asking you to hold fast to that faith written into our founding documents that idea whispered by slaves and abolitionists that spirit sung by immigrants and homesteaders and those who marched for justice that creed reaffirmed by those who planted flags from foreign battlefields to the surface of the moon a creed at the core of every american whose story is not yet written yes we can yes we did yes we can thank you god bless you may god continue to bless the united states of america thank you thank you thank you thank you thank you thank you thank you thank you thank you thank you thank you'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_transcription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LG2OBVj5LDjL",
    "outputId": "aa604af6-5628-44e7-968a-d8d59c6a8417"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.395, 0.033, array([0.1, 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0.1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_emotionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-ndjKVzLJ8Z",
    "outputId": "4e53884d-b8d2-4839-883e-0c666b82d0dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87209, {'thank you': 12, 'right': 1}, {'thank you': 12})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_filler_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvNf1uw1LMFm",
    "outputId": "4361a483-3442-494e-c438-4c089d17411c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), [])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_speech_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwaDnGwTLT9R",
    "outputId": "0429f3e8-37bc-4e66-a629-b3904f3f84b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([0.058 , 0.0475, 0.059 , 0.0415, 0.039 , 0.0245, 0.046 , 0.0825,\n",
       "        0.109 ]),\n",
       " [])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_background_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJGLKRZcLVsu",
    "outputId": "98f4a34e-de4e-4577-f37c-c6725fab385e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7701390578413834,\n",
       " array([0.866, 0.762, 0.753, 0.767, 0.769, 0.78 , 0.763, 0.734, 0.748]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_intelligibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVlShanfLV6j",
    "outputId": "e73d7a9f-1479-49d4-b85b-9cb9bbb3b36f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.698, array([0.846, 0.475, 0.454, 0.367, 0.562, 0.962, 0.958, 0.929, 0.732]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_incorrect_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPq4LHc4LWGR",
    "outputId": "b33dc072-77ea-49d7-f7c9-f58415c4bb78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.555, array([0.633, 0.   , 0.719, 0.604, 0.529, 0.41 , 0.553, 0.649, 0.896]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_incorrect_glances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69_yaU1zLWgz",
    "outputId": "79b42430-bb5d-4029-ead7-dade5e13d27f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, array([2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_gestures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jDLDPH1LWsL",
    "outputId": "3cf39a69-e325-4d70-a5a4-4cd36003a9c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing.get_clothes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdwxJIdwXXv1",
    "outputId": "bb7134a1-e0b6-4a9a-d3bf-83d46fbecbaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotionality': array([0.1, 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0.1]), 'speech_rate': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'background_noise': array([0.058 , 0.0475, 0.059 , 0.0415, 0.039 , 0.0245, 0.046 , 0.0825,\n",
      "       0.109 ]), 'intelligibility': array([0.866, 0.762, 0.753, 0.767, 0.769, 0.78 , 0.763, 0.734, 0.748]), 'glances': array([0.633, 0.   , 0.719, 0.604, 0.529, 0.41 , 0.553, 0.649, 0.896]), 'gestures': array([2, 2, 2, 2, 2, 2, 2, 2, 2])}\n",
      "background_noise [0.058  0.0475 0.059  0.0415 0.039  0.0245 0.046  0.0825 0.109 ]\n",
      "speech_rate [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "emotionality [0.1 0.  0.  0.  0.  0.  0.1 0.  0.1]\n",
      "intelligibility [0.866 0.762 0.753 0.767 0.769 0.78  0.763 0.734 0.748]\n",
      "gestures [2 2 2 2 2 2 2 2 2]\n",
      "glances [0.633 0.    0.719 0.604 0.529 0.41  0.553 0.649 0.896]\n",
      "[['Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума', 'Нет фонового шума'], ['Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи', 'Оптимальный темп речи'], ['Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции', 'Преимущественно желаемые эмоции'], ['Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива', 'Речь полностью разборчива'], ['Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция', 'Активная жестикуляция'], ['Вы часто отводите взгляд', None, 'Вы часто отводите взгляд', 'Вы часто отводите взгляд', None, None, None, 'Вы часто отводите взгляд', 'Вы часто отводите взгляд'], ['Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение', 'Слишком темное освещение']]\n",
      "[[True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True], [False, False, False, False, False, False, False, False, False], [False, True, False, False, True, True, True, False, False], [False, False, False, False, False, False, False, False, False]]\n",
      "Moviepy - Building video short_eng_painted.mp4.\n",
      "MoviePy - Writing audio in short_eng_paintedTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video short_eng_painted.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready short_eng_painted.mp4\n"
     ]
    }
   ],
   "source": [
    "painted_path = processing.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "Y2TggR_cuXa8",
    "outputId": "3d40f481-d230-4f0f-fbc5-330166d6e875"
   },
   "outputs": [],
   "source": [
    "video_path = painted_path\n",
    "video_clip = VideoFileClip(video_path)\n",
    "#video_clip.ipython_display(width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
